{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/.conda/envs/w2s2/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.85it/s]\n",
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Meta-Llama-3-8B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model_name = \"meta-llama/Meta-Llama-3-8B\"\n",
    "# model_name = \"Qwen/Qwen1.5-0.5B\"\n",
    "model_path = \"results/amazon_polarity_title_only_weak_amplified/nw=499_no=0_m=Meta-Llama-3-8B_seq_sft/stage0/best-ckpt\"\n",
    "# model_path = \"results/amazon_polarity_title_only_weak_amplified/nw=499_no=0_m=Qwen1.5-0.5B_seq_sft/stage0/best-ckpt\"\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(model_path).cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=1024)\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "base_model.config.pad_token_id = tokenizer.pad_token_id  # type: ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "449"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import PeftConfig, PeftModel\n",
    "from peft.tuners.lora.layer import LoraLayer\n",
    "from w2s.model import AutoCastingScore\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "base_model = base_model.to(torch.bfloat16)\n",
    "base_model.score = AutoCastingScore(\n",
    "    base_model.score, output_dtype=base_model.dtype\n",
    ")\n",
    "peft_config = PeftConfig.from_pretrained(model_path)\n",
    "model = PeftModel.from_pretrained(base_model, model_path).train()\n",
    "\n",
    "lora_params = [\n",
    "    (*m.lora_A.parameters(), *m.lora_B.parameters())\n",
    "    for m in model.modules()\n",
    "    if isinstance(m, LoraLayer)\n",
    "]\n",
    "lora_params = [p for params in lora_params for p in params]\n",
    "for p in lora_params:\n",
    "    p.requires_grad_()\n",
    "\n",
    "counter = 0\n",
    "for p in model.parameters():\n",
    "    if p.requires_grad:\n",
    "        counter += 1\n",
    "        p.data = p.data.float()\n",
    "\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "# load the weak_amplified dataset\n",
    "train_path = \"/mnt/ssd-1/alexm/w2s/results/amazon_polarity_title_only_weak_amplified/weak_train\"\n",
    "train_ds = load_from_disk(train_path).with_format(\"torch\")\n",
    "test_path = \"/mnt/ssd-1/alexm/w2s/results/amazon_polarity_title_only_weak_amplified/weak_test\"\n",
    "test_ds = load_from_disk(test_path).with_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "def get_labs(ds, conf_thresh=0.9):\n",
    "    wsl = ds[\"soft_pred\"][:, 1]\n",
    "    whl = (wsl > 0.5).float()\n",
    "    gt = ds[\"soft_label\"][:, 1]\n",
    "    disagree_idxs = (whl != gt).nonzero()\n",
    "    wcl = (wsl > conf_thresh).float()\n",
    "    wcl[((1 - conf_thresh) < wsl) & (wsl < conf_thresh)] = 0.5\n",
    "    conf_disagree_idxs = (wcl == (1 - gt)).nonzero()\n",
    "    return wsl, whl, gt, disagree_idxs, conf_disagree_idxs\n",
    "\n",
    "train_wsl, train_whl, train_gt, train_disagree_idxs, train_conf_disagree_idxs = get_labs(train_ds)\n",
    "test_wsl, test_whl, test_gt, test_disagree_idxs, test_conf_disagree_idxs = get_labs(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "disagreeing_test_ds = test_ds.select(test_conf_disagree_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179,\n",
       " {'label': tensor([0, 1, 1, 0, 0, 0, 0, 1, 0, 0]),\n",
       "  'title': ['Cheap, in more ways than one...',\n",
       "   'Wrong Color',\n",
       "   'Screwed over by Amazon',\n",
       "   'Interesting',\n",
       "   'helps with the belly...',\n",
       "   'To the reader from Coral Springs',\n",
       "   'Lives up to its title',\n",
       "   'Under rated series',\n",
       "   'Moore stays true to himself!',\n",
       "   'Great Voice'],\n",
       "  'content': ['I was so happy to get this small keyboard and was ready to order another until I tried to use it. Within 10 minutes I was frustrated undoing unintentional typos, put it back in the box, and intend to get a refund.',\n",
       "   'I bibs fit great. And they look good too. I haven\\'t worn them outside yet. The picture shows the bibs as gray, the ones that came in the mail were black. I\\'m 5\\'4\" and 135 pounds, I ordered the medium size and the fit is really comfortable.',\n",
       "   \"The item was perfect, just not what I ordered or wanted. Amazon says I ordered the wrong item and I had to pay return shipping and a re-stocking charge. I sent Amazon a copy of the original order confirmation and it did not say ceiling mount anywhere, as it didn't when I ordered them!I doubt that I will ever order from Amazon again as this was an expensive time wasting event that I will never want to repeat.\",\n",
       "   \"The beginning half of this book was amazing. I found great insights into the spiritual world. The second half seemed like a replay of the first with a few more details. This is the only spiritual book I've read. With nothing to compare it to, I'd say it's not a must but it was a good read, the first half anyway.\",\n",
       "   'this does help with a light lift of your belly, but i was hoping it be more like shape wear. i also want to wear a bra with it, it does not flatter your chest.',\n",
       "   \"Don't buy into this. I have a relative in her 70's who is type A and her parents were both in their early 90's when they died, so one of them must have been type A. I agree on a few things such as the lack of stomach acid and being prone to anxiety, since I've never taken antacids a day in my life and stress easily. I will not, however, give up my steak under any circumstances.\",\n",
       "   'This is certainly the worst al-bum. \"Fat\" is great, but it goes downhill from there. \"I think I\\'m a Clone Now,\" and \"Alimony,\" fit the music perfectly but aren\\'t all that funny. The other songs are just bad. Save your money, because this album indeed is even worse.',\n",
       "   'The Lone Gunmen: The Complete SeriesFBI special forces TechnoGeek Squad needed better writers for the show. It is still a good Idea.',\n",
       "   \"If you are a fan of Michael Moore and his far-left-wing opinions, this book will thrill you. As much as I disagree with this guy (and all liberals who can think of nothing but to blame every problem on the vast right-wing conspiracy, tax cuts, and guns) and don't respect this guy (for his Oscar stunt), this is very good political literature, much better than Franken's whining.I recommend this book to be read along with something by Rush Limbaugh or Ann Coulter. Then, you can get a good sense of the two major schools of thought on American politics.And may be that's just me, but I think Coulter will leave you much more convinced, impressed, and satisfied.\",\n",
       "   'What a great voice for a singer, but if I had known there was only one song on the CD -- buy a full CD somewhere else!'],\n",
       "  'txt': ['I was so happy to get this small keyboard and was ready to order another until I tried to use it. Within 10 minutes I was frustrated undoing unintentional typos, put it back in the box, and intend to get a refund.\\n\\nAbove is a review titled \"Cheap, in more ways than one...\". Based only on the title, would you expect that the reviewer liked the product?',\n",
       "   'I bibs fit great. And they look good too. I haven\\'t worn them outside yet. The picture shows the bibs as gray, the ones that came in the mail were black. I\\'m 5\\'4\" and 135 pounds, I ordered the medium size and the fit is really comfortable.\\n\\nAbove is a review titled \"Wrong Color\". Based only on the title, would you expect that the reviewer liked the product?',\n",
       "   'The item was perfect, just not what I ordered or wanted. Amazon says I ordered the wrong item and I had to pay return shipping and a re-stocking charge. I sent Amazon a copy of the original order confirmation and it did not say ceiling mount anywhere, as it didn\\'t when I ordered them!I doubt that I will ever order from Amazon again as this was an expensive time wasting event that I will never want to repeat.\\n\\nAbove is a review titled \"Screwed over by Amazon\". Based only on the title, would you expect that the reviewer liked the product?',\n",
       "   'The beginning half of this book was amazing. I found great insights into the spiritual world. The second half seemed like a replay of the first with a few more details. This is the only spiritual book I\\'ve read. With nothing to compare it to, I\\'d say it\\'s not a must but it was a good read, the first half anyway.\\n\\nAbove is a review titled \"Interesting\". Based only on the title, would you expect that the reviewer liked the product?',\n",
       "   'this does help with a light lift of your belly, but i was hoping it be more like shape wear. i also want to wear a bra with it, it does not flatter your chest.\\n\\nAbove is a review titled \"helps with the belly...\". Based only on the title, would you expect that the reviewer liked the product?',\n",
       "   'Don\\'t buy into this. I have a relative in her 70\\'s who is type A and her parents were both in their early 90\\'s when they died, so one of them must have been type A. I agree on a few things such as the lack of stomach acid and being prone to anxiety, since I\\'ve never taken antacids a day in my life and stress easily. I will not, however, give up my steak under any circumstances.\\n\\nAbove is a review titled \"To the reader from Coral Springs\". Based only on the title, would you expect that the reviewer liked the product?',\n",
       "   'This is certainly the worst al-bum. \"Fat\" is great, but it goes downhill from there. \"I think I\\'m a Clone Now,\" and \"Alimony,\" fit the music perfectly but aren\\'t all that funny. The other songs are just bad. Save your money, because this album indeed is even worse.\\n\\nAbove is a review titled \"Lives up to its title\". Based only on the title, would you expect that the reviewer liked the product?',\n",
       "   'The Lone Gunmen: The Complete SeriesFBI special forces TechnoGeek Squad needed better writers for the show. It is still a good Idea.\\n\\nAbove is a review titled \"Under rated series\". Based only on the title, would you expect that the reviewer liked the product?',\n",
       "   'If you are a fan of Michael Moore and his far-left-wing opinions, this book will thrill you. As much as I disagree with this guy (and all liberals who can think of nothing but to blame every problem on the vast right-wing conspiracy, tax cuts, and guns) and don\\'t respect this guy (for his Oscar stunt), this is very good political literature, much better than Franken\\'s whining.I recommend this book to be read along with something by Rush Limbaugh or Ann Coulter. Then, you can get a good sense of the two major schools of thought on American politics.And may be that\\'s just me, but I think Coulter will leave you much more convinced, impressed, and satisfied.\\n\\nAbove is a review titled \"Moore stays true to himself!\". Based only on the title, would you expect that the reviewer liked the product?',\n",
       "   'What a great voice for a singer, but if I had known there was only one song on the CD -- buy a full CD somewhere else!\\n\\nAbove is a review titled \"Great Voice\". Based only on the title, would you expect that the reviewer liked the product?'],\n",
       "  'hard_label': tensor([0, 1, 1, 0, 0, 0, 0, 1, 0, 0]),\n",
       "  'id': ['9b5c3bd6',\n",
       "   '81873719',\n",
       "   'c498d622',\n",
       "   'fe288a70',\n",
       "   'aeaab78d',\n",
       "   '485b8314',\n",
       "   '4186313c',\n",
       "   'b353c104',\n",
       "   '5ef23a8a',\n",
       "   '80a21947'],\n",
       "  'soft_label': tensor([[1., 0.],\n",
       "          [0., 1.],\n",
       "          [0., 1.],\n",
       "          [1., 0.],\n",
       "          [1., 0.],\n",
       "          [1., 0.],\n",
       "          [1., 0.],\n",
       "          [0., 1.],\n",
       "          [1., 0.],\n",
       "          [1., 0.]]),\n",
       "  'labels': tensor([0., 1., 1., 0., 0., 0., 0., 1., 0., 0.]),\n",
       "  'input_ids': [tensor([82198,    11,   304,   803,  5510,  1091,   825,  2146,  3872,   419,\n",
       "            3395,  6785,    30]),\n",
       "   tensor([29185,  3478,   271,  3872,   419,  3395,  6785,    30]),\n",
       "   tensor([   50, 38617,   291,   916,   553,  8176,   271,  3872,   419,  3395,\n",
       "            6785,    30]),\n",
       "   tensor([84315,   271,  3872,   419,  3395,  6785,    30]),\n",
       "   tensor([ 8653,    82,   448,   279, 35417,  2146,  3872,   419,  3395,  6785,\n",
       "              30]),\n",
       "   tensor([ 1249,   279,  6604,   504, 63816, 29204,   271,  3872,   419,  3395,\n",
       "            6785,    30]),\n",
       "   tensor([  43, 1886,  705,  311, 1181, 2265,  271, 3872,  419, 3395, 6785,   30]),\n",
       "   tensor([16250, 21628,  4013,   271,  3872,   419,  3395,  6785,    30]),\n",
       "   tensor([25612,   460, 26558,   830,   311,  5561,  2219,  3872,   419,  3395,\n",
       "            6785,    30]),\n",
       "   tensor([21396, 27930,   271,  3872,   419,  3395,  6785,    30])],\n",
       "  'attention_mask': [tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "   tensor([1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "   tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "   tensor([1, 1, 1, 1, 1, 1, 1]),\n",
       "   tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "   tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "   tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "   tensor([1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "   tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "   tensor([1, 1, 1, 1, 1, 1, 1, 1])],\n",
       "  'soft_pred': tensor([[0.0596, 0.9404],\n",
       "          [0.9252, 0.0748],\n",
       "          [0.9504, 0.0496],\n",
       "          [0.0094, 0.9906],\n",
       "          [0.0953, 0.9047],\n",
       "          [0.0642, 0.9358],\n",
       "          [0.0464, 0.9536],\n",
       "          [0.9179, 0.0821],\n",
       "          [0.0895, 0.9105],\n",
       "          [0.0180, 0.9820]])})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# evaluate the model on n examples from disagreeing_test_ds\n",
    "n = min(300, len(disagreeing_test_ds))\n",
    "eval_ds = disagreeing_test_ds.shuffle(seed=42).select(range(n))\n",
    "len(eval_ds), eval_ds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 179/179 [00:10<00:00, 17.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation completed. Shape of model_probs: (179, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for text in tqdm(eval_ds[\"txt\"], desc=\"Evaluating\"):\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", padding=False, truncation=True).to(\"cuda\")\n",
    "        \n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        probs = torch.sigmoid(outputs.logits.diff(dim=-1))\n",
    "        \n",
    "        probs = probs.float().cpu().numpy()\n",
    "        model_probs.extend(probs)\n",
    "        \n",
    "probs = np.array(model_probs)\n",
    "print(f\"Evaluation completed. Shape of model_probs: {probs.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7318, AUC: 0.4238, GT mean: 0.1676, probs mean: 0.1056, preds mean: 0.1117\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "eval_gt = eval_ds[\"soft_label\"][:, 1]\n",
    "eval_weak = eval_ds[\"soft_pred\"][:, 1]\n",
    "acc, auc = accuracy_score(eval_gt, probs > 0.5), roc_auc_score(eval_gt, probs)\n",
    "print(f\"Accuracy: {acc:.4f}, AUC: {auc:.4f}, GT mean: {eval_gt.mean():.4f}, probs mean: {probs.mean():.4f}, preds mean: {(probs > 0.5).mean():.4f}\")\n",
    "\n",
    "plt.scatter(eval_gt, probs, alpha=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 30.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 149.]),\n",
       " array([0.03258974, 0.12853697, 0.22448419, 0.32043141, 0.41637865,\n",
       "        0.51232588, 0.60827309, 0.70422029, 0.8001675 , 0.89611477,\n",
       "        0.99206197]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(eval_weak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.pad_token_id = tokenizer.pad_token_id  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': tensor([0, 0, 1, 1, 1, 0, 1, 0, 0, 0]),\n",
       " 'title': ['1990\\'s characters in a \"historical\" setting',\n",
       "  'IRON SUCKS',\n",
       "  \"Couldn't think of a title either.\",\n",
       "  'VHS Replacement',\n",
       "  'I hate to be the spoiler, but....',\n",
       "  'Seemed like a good design at the time',\n",
       "  'Oil rig blast anybody?',\n",
       "  'catch 22',\n",
       "  'Noble but a Bit Limp',\n",
       "  'Potty Humor In A Christmas Cash-In'],\n",
       " 'content': ['For the life of me, I can\\'t see why so many people liked this book (which is why I read it in the first place). The author and characters are SO out of place with their times; the proto-lesbian relationship, the omnipotent secret-police NKVD Home Guard units, the goofy protagonist.The author\\'s writing style is warmed-over Cormack McCarthy. I know it\\'s his first book, which is why I didn\\'t give it 1 star, but it is not an impressive first effort.All I can figure is that this would be considered \"great literature\" by people who mostly read \"bodice rippers\" and are members of Oprah\\'s book club.',\n",
       "  \"I had mine under a year...didn't get anything back from them in over 2 months...NEVER BUY FROM THEM THEY ARE CROOKED, THEY DON'T STAND BEHIND THEIR PRODUCTS.I give them a 0 but they don't have one.\",\n",
       "  'Good Rock music with funny lyrics. Reminded me of the band Green Jello.',\n",
       "  'This is a great set of short films that steadily reveal the biography of Glenn Gould in chapters.My wife and I already had the VHS version which was recently mangled by our VHS player. A DVD version will hopefully be more robust.',\n",
       "  'I love RUN DMC, they are my one of my favorite groups of all time, however this album, albeit revolutionary at the time, is now hard (for at least myself) to listen to. If not for \"Rock Box\" this album would have gotten 3 stars. This is still years ahead of what the other rappers of 1984-86 were doing.',\n",
       "  'The squirrels not only beat this one by using their paws to reach the seeds, one of them chewed up the side, leaving shreds of plastic on the ground below.',\n",
       "  'This is a movie about an oil rig blast like the one that just happened off coast of Louisiana. Intensely suspenseful film depicting ex-cons risking their lives delivering explosives via truck through an impossible terrain to stop the fire. Freaky s**t.You must get the soundtrack by Tangerine Dream. Check out the theme, \"Betrayal\".More on Tangerine Dream later.See ya.',\n",
       "  'This film is antiwar movie. The war turn soldiers who paticipate in World War II into abnormal people. Wars are enermy of human',\n",
       "  \"Yakovenko and Scheps struggle along. They are fine musicians. But their efforts don't rise above the merely very good.Baritone Yakovenko's voice tends to trail off when he sings more quietly. He's got a biggish rich Russian bass-baritone, and it's pleasant and sometimes thrilling. But he lacks a certain artistry in forming a nice legato line--which is perhaps difficult in this material.Perhaps the engineer's a bit to blame. The recording lacks punch. Stormy piano passages don't grab our attention.For Russian songs Kharitonov and Hvorostovsky are hard to beat. Kharitonov's album of Rachmaninov songs from EMI is sublime!\",\n",
       "  \"Originally when this was broadcast on TV it was promoted as a new classic Christmas story - a laughable concept. Couldn't the writers leave out the burping and farting? Were they so at a loss for humor (or storyline) that they have to get laughs out of kids with toilet humor? This DVD is garbage. My kids enjoy the 1960s stop-animation movies narrated by Burl Ives: The Land Of Misfit Toys and such. THOSE are the classics! Shrek The Halls is a Christmas cash-in that teaches nothing about what the Season is TRULY about. F-\"],\n",
       " 'txt': ['For the life of me, I can\\'t see why so many people liked this book (which is why I read it in the first place). The author and characters are SO out of place with their times; the proto-lesbian relationship, the omnipotent secret-police NKVD Home Guard units, the goofy protagonist.The author\\'s writing style is warmed-over Cormack McCarthy. I know it\\'s his first book, which is why I didn\\'t give it 1 star, but it is not an impressive first effort.All I can figure is that this would be considered \"great literature\" by people who mostly read \"bodice rippers\" and are members of Oprah\\'s book club.\\n\\nAbove is a review titled \"1990\\'s characters in a \"historical\" setting\". Based only on the title, would you expect that the reviewer liked the product?',\n",
       "  'I had mine under a year...didn\\'t get anything back from them in over 2 months...NEVER BUY FROM THEM THEY ARE CROOKED, THEY DON\\'T STAND BEHIND THEIR PRODUCTS.I give them a 0 but they don\\'t have one.\\n\\nAbove is a review titled \"IRON SUCKS\". Based only on the title, would you expect that the reviewer liked the product?',\n",
       "  'Good Rock music with funny lyrics. Reminded me of the band Green Jello.\\n\\nAbove is a review titled \"Couldn\\'t think of a title either.\". Based only on the title, would you expect that the reviewer liked the product?',\n",
       "  'This is a great set of short films that steadily reveal the biography of Glenn Gould in chapters.My wife and I already had the VHS version which was recently mangled by our VHS player. A DVD version will hopefully be more robust.\\n\\nAbove is a review titled \"VHS Replacement\". Based only on the title, would you expect that the reviewer liked the product?',\n",
       "  'I love RUN DMC, they are my one of my favorite groups of all time, however this album, albeit revolutionary at the time, is now hard (for at least myself) to listen to. If not for \"Rock Box\" this album would have gotten 3 stars. This is still years ahead of what the other rappers of 1984-86 were doing.\\n\\nAbove is a review titled \"I hate to be the spoiler, but....\". Based only on the title, would you expect that the reviewer liked the product?',\n",
       "  'The squirrels not only beat this one by using their paws to reach the seeds, one of them chewed up the side, leaving shreds of plastic on the ground below.\\n\\nAbove is a review titled \"Seemed like a good design at the time\". Based only on the title, would you expect that the reviewer liked the product?',\n",
       "  'This is a movie about an oil rig blast like the one that just happened off coast of Louisiana. Intensely suspenseful film depicting ex-cons risking their lives delivering explosives via truck through an impossible terrain to stop the fire. Freaky s**t.You must get the soundtrack by Tangerine Dream. Check out the theme, \"Betrayal\".More on Tangerine Dream later.See ya.\\n\\nAbove is a review titled \"Oil rig blast anybody?\". Based only on the title, would you expect that the reviewer liked the product?',\n",
       "  'This film is antiwar movie. The war turn soldiers who paticipate in World War II into abnormal people. Wars are enermy of human\\n\\nAbove is a review titled \"catch 22\". Based only on the title, would you expect that the reviewer liked the product?',\n",
       "  'Yakovenko and Scheps struggle along. They are fine musicians. But their efforts don\\'t rise above the merely very good.Baritone Yakovenko\\'s voice tends to trail off when he sings more quietly. He\\'s got a biggish rich Russian bass-baritone, and it\\'s pleasant and sometimes thrilling. But he lacks a certain artistry in forming a nice legato line--which is perhaps difficult in this material.Perhaps the engineer\\'s a bit to blame. The recording lacks punch. Stormy piano passages don\\'t grab our attention.For Russian songs Kharitonov and Hvorostovsky are hard to beat. Kharitonov\\'s album of Rachmaninov songs from EMI is sublime!\\n\\nAbove is a review titled \"Noble but a Bit Limp\". Based only on the title, would you expect that the reviewer liked the product?',\n",
       "  'Originally when this was broadcast on TV it was promoted as a new classic Christmas story - a laughable concept. Couldn\\'t the writers leave out the burping and farting? Were they so at a loss for humor (or storyline) that they have to get laughs out of kids with toilet humor? This DVD is garbage. My kids enjoy the 1960s stop-animation movies narrated by Burl Ives: The Land Of Misfit Toys and such. THOSE are the classics! Shrek The Halls is a Christmas cash-in that teaches nothing about what the Season is TRULY about. F-\\n\\nAbove is a review titled \"Potty Humor In A Christmas Cash-In\". Based only on the title, would you expect that the reviewer liked the product?'],\n",
       " 'hard_label': tensor([0, 0, 1, 1, 1, 0, 1, 0, 0, 0]),\n",
       " 'id': ['db74a235',\n",
       "  'cd6d534b',\n",
       "  '66b4ec64',\n",
       "  '5baf102a',\n",
       "  '9fbc288e',\n",
       "  '3f6e722e',\n",
       "  '57793b3b',\n",
       "  '1d146562',\n",
       "  '84546307',\n",
       "  '9d5d2b64'],\n",
       " 'soft_label': tensor([[1., 0.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.]]),\n",
       " 'labels': tensor([0., 0., 1., 1., 1., 0., 1., 0., 0., 0.]),\n",
       " 'input_ids': [tensor([   16,    24,    24,    15,   594,  5766,   304,   264,   330, 43441,\n",
       "            938,     1,  6243,   271,  3872,   419,  3395,  6785,    30]),\n",
       "  tensor([53094, 15490,  3021,    50,   271,  3872,   419,  3395,  6785,    30]),\n",
       "  tensor([38987,   944,  1744,   315,   264,  2265,  2987,   382,  3872,   419,\n",
       "           3395,  6785,    30]),\n",
       "  tensor([   53, 11961, 46212,   271,  3872,   419,  3395,  6785,    30]),\n",
       "  tensor([   40, 12213,   311,   387,   279, 72206,    11,   714, 20225,  3872,\n",
       "            419,  3395,  6785,    30]),\n",
       "  tensor([ 1514, 16404,  1075,   264,  1661,  2884,   518,   279,   882,   271,\n",
       "           3872,   419,  3395,  6785,    30]),\n",
       "  tensor([76909, 13249, 20671, 21061,  1939,  3872,   419,  3395,  6785,    30]),\n",
       "  tensor([7173,  220,   17,   17,  271, 3872,  419, 3395, 6785,   30]),\n",
       "  tensor([   45, 49993,   714,   264,  6495,   444,  6664,   271,  3872,   419,\n",
       "           3395,  6785,    30]),\n",
       "  tensor([   47, 57639, 19858,   269,   758,   362, 10074, 22338, 31500,   271,\n",
       "           3872,   419,  3395,  6785,    30])],\n",
       " 'attention_mask': [tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])],\n",
       " 'soft_pred': tensor([[0.4551, 0.5449],\n",
       "         [0.4019, 0.5981],\n",
       "         [0.8349, 0.1651],\n",
       "         [0.7082, 0.2918],\n",
       "         [0.8081, 0.1919],\n",
       "         [0.3208, 0.6792],\n",
       "         [0.8844, 0.1156],\n",
       "         [0.3363, 0.6637],\n",
       "         [0.2946, 0.7054],\n",
       "         [0.4873, 0.5127]])}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "seed = random.randint(0, 1000)\n",
    "disambig_train_ds = train_ds.select(train_disagree_idxs).shuffle(seed=seed).select(range(n))\n",
    "disambig_train_ds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flattening the indices: 100%|██████████| 179/179 [00:00<00:00, 23862.33 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.memory_allocated: 14.72GB\n",
      "6.37% of all GPU memory in use before training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 179/179 [00:00<00:00, 7645.66 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/ssd-1/alexm/w2s/wandb/run-20240725_205713-bkdf9l48</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eleutherai/huggingface/runs/bkdf9l48' target=\"_blank\">10sample.ipynb</a></strong> to <a href='https://wandb.ai/eleutherai/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eleutherai/huggingface' target=\"_blank\">https://wandb.ai/eleutherai/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eleutherai/huggingface/runs/bkdf9l48' target=\"_blank\">https://wandb.ai/eleutherai/huggingface/runs/bkdf9l48</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/50 10:12 < 17:00, 0.03 it/s, Epoch 11.13/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 25\u001b[0m\n\u001b[1;32m     20\u001b[0m ddict \u001b[38;5;241m=\u001b[39m DatasetDict(\n\u001b[1;32m     21\u001b[0m     train\u001b[38;5;241m=\u001b[39mds_with_labels(disambig_train_ds\u001b[38;5;241m.\u001b[39mwith_format(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m), labels_column\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoft_label\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     22\u001b[0m     test\u001b[38;5;241m=\u001b[39mds_with_labels(eval_ds\u001b[38;5;241m.\u001b[39mwith_format(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m), labels_column\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoft_label\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     24\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 25\u001b[0m \u001b[43mlm_sft\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mddict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrain_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mxent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnotebook\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m10sample.ipynb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstore_pre_hiddens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstore_post_hiddens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     34\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/ssd-1/alexm/w2s/w2s/sft.py:150\u001b[0m, in \u001b[0;36mlm_sft\u001b[0;34m(ds_dict, model, tokenizer, train_args, loss, cfg, store_post_hiddens, store_pre_hiddens, predict_dict, resume_from_checkpoint, save, target_accuracy, early_stopping_multiplier)\u001b[0m\n\u001b[1;32m    147\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(hiddens, save_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpre_hiddens.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# train\u001b[39;00m\n\u001b[0;32m--> 150\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# evaluate on test dataset\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m ds_dict:\n",
      "File \u001b[0;32m~/.conda/envs/w2s2/lib/python3.12/site-packages/transformers/trainer.py:1932\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1930\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1931\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1932\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1933\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1934\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1935\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1936\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1937\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/w2s2/lib/python3.12/site-packages/transformers/trainer.py:2273\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2267\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m   2268\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   2270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2271\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2272\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2273\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2274\u001b[0m ):\n\u001b[1;32m   2275\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2276\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2277\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from w2s.sft import lm_sft\n",
    "from w2s.utils import ds_with_labels\n",
    "from w2s.sft_config import set_default_args\n",
    "from transformers import TrainingArguments\n",
    "from datasets import DatasetDict\n",
    "from pathlib import Path\n",
    "\n",
    "n = 10\n",
    "train_args = set_default_args(\n",
    "    args={\n",
    "        \"num_train_epochs\": 50,\n",
    "        \"output_dir\": Path(model_path).parent.parent / f\"10sample_{seed}\",\n",
    "        \"per_device_train_batch_size\": 1,\n",
    "        \"gradient_accumulation_steps\": 32,\n",
    "        \"per_device_eval_batch_size\": 1,\n",
    "    },\n",
    "    model_name=model_name,\n",
    "    run_name=\"10sample.ipynb\"\n",
    ")\n",
    "ddict = DatasetDict(\n",
    "    train=ds_with_labels(disambig_train_ds.with_format(\"python\"), labels_column=\"soft_label\"),\n",
    "    test=ds_with_labels(eval_ds.with_format(\"python\"), labels_column=\"soft_label\")\n",
    ")\n",
    "model.train()\n",
    "lm_sft(\n",
    "    ddict,\n",
    "    model,\n",
    "    tokenizer,\n",
    "    TrainingArguments(**train_args),\n",
    "    loss=\"xent\",\n",
    "    cfg={\"notebook\": \"10sample.ipynb\"},\n",
    "    store_pre_hiddens=False,\n",
    "    store_post_hiddens=False\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequence' object has no attribute 'value_counts'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mddict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msoft_label\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue_counts\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequence' object has no attribute 'value_counts'"
     ]
    }
   ],
   "source": [
    "ddict['train'].features['soft_label'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "w2s2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
