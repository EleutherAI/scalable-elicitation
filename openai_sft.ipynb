{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import random\n",
    "from hashlib import md5\n",
    "rng = random.Random(42)\n",
    "\n",
    "def get_prompts(row, rng):\n",
    "    hard_label = int(rng.random() < 0.5)\n",
    "    if hard_label:\n",
    "        ans = row[\"choices\"][int(row[\"answer\"])]\n",
    "    else:\n",
    "        ans = rng.choice(\n",
    "            [c for i, c in enumerate(row[\"choices\"]) if i != int(row[\"answer\"])]\n",
    "        )\n",
    "\n",
    "    choices = \"\\n\".join(row[\"choices\"])\n",
    "    txt = f\"{row['question']}\\n\\n{choices}\\n\\nA: {ans}.\"\n",
    "    completion = {\"prompt\": txt, \"completion\": \" Yes\" if hard_label else \" No\"}\n",
    "    messages = {\"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": txt},\n",
    "        {\"role\": \"assistant\", \"content\": \"Yes\" if hard_label else \"No\"},\n",
    "    ]}\n",
    "    return {\"id\": md5(txt.encode()).hexdigest()[-8:], \"messages\": messages, \"completion\": completion, \"hard_label\": hard_label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/.conda/envs/w2s2/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# load MMLU, splitting it into a train and test set\n",
    "# train a weak model (e.g. babbage)\n",
    "# get predictions on train and test (including logprobs)\n",
    "# save these predictions\n",
    "# shuffle train and get a val set\n",
    "# train a 4o on the train set, early stopping on val set\n",
    "# get predictions on test set, including logprobs\n",
    "# get accuracy on test set and save the num_weak, num_strong, num_epochs, val_acc, test_acc, and predictions\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "ds = load_dataset(\"cais/mmlu\", \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'subject', 'choices', 'answer'],\n",
       "    num_rows: 15858\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = concatenate_datasets([ds[\"test\"], ds[\"validation\"], ds[\"dev\"]])\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'subject', 'choices', 'answer', 'id', 'messages', 'completion', 'hard_label'],\n",
       "    num_rows: 15858\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_ds = ds.map(partial(get_prompts, rng=rng))\n",
    "binary_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "splits = binary_ds.shuffle(seed=0).train_test_split(test_size=1000/len(binary_ds))\n",
    "subsplits = splits[\"train\"].train_test_split(test_size=500/len(splits[\"train\"]))\n",
    "splits = {\n",
    "    \"train\": subsplits[\"train\"],\n",
    "    \"val\": subsplits[\"test\"],\n",
    "    \"test\": splits[\"test\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save jsonls\n",
    "import json\n",
    "\n",
    "for split_name, split in splits.items():\n",
    "    with open(f\"openai/{split_name}.jsonl\", \"w\") as f:\n",
    "        f.write(\"\\n\".join([json.dumps(d) for d in split[\"completion\"]]))\n",
    "\n",
    "n = 3000\n",
    "small_train = splits[\"train\"].select(range(n))\n",
    "with open(f\"openai/train{n}.jsonl\", \"w\") as f:\n",
    "    f.write(\"\\n\".join([json.dumps(d) for d in small_train[\"completion\"]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# finetune weak model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-VJuHa1O8tYpZiBPl00RhZuW6', bytes=1654821, created_at=1723226415, filename='train3000.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.files.create(\n",
    "    file=open(f\"openai/train{n}.jsonl\", \"rb\"),\n",
    "    purpose=\"fine-tune\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-DpbDksSRdN0GSu3EzKbTEKte', bytes=266589, created_at=1723226420, filename='val.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.files.create(\n",
    "    file=open(\"openai/val.jsonl\", \"rb\"),\n",
    "    purpose=\"fine-tune\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-qNsCRUUZU726tnqnTqncnrPs', created_at=1723226442, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='davinci-002', object='fine_tuning.job', organization_id='org-5KzWCdbJZtVYV7zk2r3Ekq9H', result_files=[], seed=789730328, status='validating_files', trained_tokens=None, training_file='file-VJuHa1O8tYpZiBPl00RhZuW6', validation_file='file-GTrAajQvRCfpmyc52o6vtRxh', estimated_finish=None, integrations=[FineTuningJobWandbIntegrationObject(type='wandb', wandb=FineTuningJobWandbIntegration(project='openai-sft', entity=None, name=None, tags=None, run_id='ftjob-qNsCRUUZU726tnqnTqncnrPs'))], user_provided_suffix='davinci-mmlu')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "client.fine_tuning.jobs.create(\n",
    "  training_file=\"file-VJuHa1O8tYpZiBPl00RhZuW6\",\n",
    "  validation_file=\"file-GTrAajQvRCfpmyc52o6vtRxh\",\n",
    "  model=\"davinci-002\",\n",
    "  suffix = \"davinci-mmlu\",\n",
    "  integrations=[{\"type\": \"wandb\", \"wandb\": {\"project\": \"openai-sft\"}}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJob](data=[FineTuningJob(id='ftjob-SX87lGJ0rqQckmxTfD0rMuix', created_at=1723225303, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='davinci-002', object='fine_tuning.job', organization_id='org-5KzWCdbJZtVYV7zk2r3Ekq9H', result_files=[], seed=165571620, status='validating_files', trained_tokens=None, training_file='file-tooC3SBdzF2CcZ5Kr9FTlPCl', validation_file='file-GTrAajQvRCfpmyc52o6vtRxh', estimated_finish=None, integrations=[FineTuningJobWandbIntegrationObject(type='wandb', wandb=FineTuningJobWandbIntegration(project='openai-sft', entity=None, name=None, tags=None, run_id='ftjob-SX87lGJ0rqQckmxTfD0rMuix'))], user_provided_suffix='davinci-mmlu'), FineTuningJob(id='ftjob-RH2Vluya5TCK6C0jytfBO64g', created_at=1723224466, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:babbage-002:personal:babbage-mmlu:9uNrv2rF', finished_at=1723225146, hyperparameters=Hyperparameters(n_epochs=1, batch_size=9, learning_rate_multiplier=16), model='babbage-002', object='fine_tuning.job', organization_id='org-5KzWCdbJZtVYV7zk2r3Ekq9H', result_files=['file-LZqanKrmi6eQgjScMkbF6ctb'], seed=2072504852, status='succeeded', trained_tokens=1534019, training_file='file-tooC3SBdzF2CcZ5Kr9FTlPCl', validation_file='file-GTrAajQvRCfpmyc52o6vtRxh', estimated_finish=None, integrations=[FineTuningJobWandbIntegrationObject(type='wandb', wandb=FineTuningJobWandbIntegration(project='openai-sft', entity=None, name=None, tags=None, run_id='ftjob-RH2Vluya5TCK6C0jytfBO64g'))], user_provided_suffix='babbage-mmlu'), FineTuningJob(id='ftjob-5UVV7noQCMWfJ1ciMIRky4g9', created_at=1723220287, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=1, batch_size=9, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-5KzWCdbJZtVYV7zk2r3Ekq9H', result_files=[], seed=590099866, status='cancelled', trained_tokens=None, training_file='file-atfIoUOhbLJSYfqiFv0ZxCbU', validation_file='file-XWEaCUPCFy8nFiyoeSNfnFvh', estimated_finish=1723227713, integrations=[FineTuningJobWandbIntegrationObject(type='wandb', wandb=FineTuningJobWandbIntegration(project='openai-sft', entity=None, name=None, tags=None, run_id='ftjob-5UVV7noQCMWfJ1ciMIRky4g9'))], user_provided_suffix='gpt-3.5-turbo-mmlu'), FineTuningJob(id='ftjob-7ZpJPuwXp8uZB3nzvudqlEOv', created_at=1723218841, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:babbage-002:personal:babbage-mmlu:9uMPTnTG', finished_at=1723219538, hyperparameters=Hyperparameters(n_epochs=3, batch_size=32, learning_rate_multiplier=16), model='babbage-002', object='fine_tuning.job', organization_id='org-5KzWCdbJZtVYV7zk2r3Ekq9H', result_files=['file-AYws5IPf4wIDplTXse77dZZM'], seed=2020585169, status='succeeded', trained_tokens=4604286, training_file='file-2yYISsH0UKXB3RY7FHn8gGcF', validation_file='file-bRJQUKG5rsfhZKLIv6a3bIVJ', estimated_finish=None, integrations=[FineTuningJobWandbIntegrationObject(type='wandb', wandb=FineTuningJobWandbIntegration(project='openai-sft', entity=None, name=None, tags=None, run_id='ftjob-7ZpJPuwXp8uZB3nzvudqlEOv'))], user_provided_suffix='babbage-mmlu'), FineTuningJob(id='ftjob-sTqKyBGf6GYjzLufhK7JRauJ', created_at=1723182142, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:babbage-002:personal:babbage-mmlu:9uCrJjyd', finished_at=1723182824, hyperparameters=Hyperparameters(n_epochs=3, batch_size=32, learning_rate_multiplier=16), model='babbage-002', object='fine_tuning.job', organization_id='org-5KzWCdbJZtVYV7zk2r3Ekq9H', result_files=['file-gjOPtcbi6vAOzVYCrVeQXO7O'], seed=1760984732, status='succeeded', trained_tokens=4599915, training_file='file-ZHYj7ydOWfC0VrO9oDyIy349', validation_file='file-7wtjaErIQuDfvcS3uWaVmHN1', estimated_finish=None, integrations=[FineTuningJobWandbIntegrationObject(type='wandb', wandb=FineTuningJobWandbIntegration(project='openai-sft', entity=None, name=None, tags=None, run_id='ftjob-sTqKyBGf6GYjzLufhK7JRauJ'))], user_provided_suffix='babbage-mmlu'), FineTuningJob(id='ftjob-gDuEdddvGvXkf1iGSQwEaEc1', created_at=1723181716, error=Error(code='invalid_training_file', message='The job failed due to an invalid training file. Invalid file format. Input file file-mpWJYy6wb4i2l4XVbrwgTHcx is in the chat-completion format, but the specified model babbage-002 is not a chat model and requires prompt-completion data. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for details.', param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=32, learning_rate_multiplier='auto'), model='babbage-002', object='fine_tuning.job', organization_id='org-5KzWCdbJZtVYV7zk2r3Ekq9H', result_files=[], seed=1357726419, status='failed', trained_tokens=None, training_file='file-mpWJYy6wb4i2l4XVbrwgTHcx', validation_file='file-lLRXvpccCM3tD0gX4Jrkunwm', estimated_finish=None, integrations=[FineTuningJobWandbIntegrationObject(type='wandb', wandb=FineTuningJobWandbIntegration(project='openai-sft', entity=None, name=None, tags=None, run_id='ftjob-gDuEdddvGvXkf1iGSQwEaEc1'))], user_provided_suffix='babbage-mmlu')], object='list', has_more=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.fine_tuning.jobs.list(limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-qNsCRUUZU726tnqnTqncnrPs', created_at=1723226442, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:davinci-002:personal:davinci-mmlu:9uOQmMSZ', finished_at=1723227307, hyperparameters=Hyperparameters(n_epochs=3, batch_size=6, learning_rate_multiplier=16), model='davinci-002', object='fine_tuning.job', organization_id='org-5KzWCdbJZtVYV7zk2r3Ekq9H', result_files=['file-c9s40uQYHtsT5R0ibAlnwxWP'], seed=789730328, status='succeeded', trained_tokens=980784, training_file='file-VJuHa1O8tYpZiBPl00RhZuW6', validation_file='file-GTrAajQvRCfpmyc52o6vtRxh', estimated_finish=None, integrations=[FineTuningJobWandbIntegrationObject(type='wandb', wandb=FineTuningJobWandbIntegration(project='openai-sft', entity=None, name=None, tags=None, run_id='ftjob-qNsCRUUZU726tnqnTqncnrPs'))], user_provided_suffix='davinci-mmlu')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.fine_tuning.jobs.retrieve(\"ftjob-qNsCRUUZU726tnqnTqncnrPs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-QPTezqVW75EVnN02wlYNw9b0', created_at=1723227314, level='info', message='The job has successfully completed', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-ZE3G9B2IZ6fjW51pfG697aTL', created_at=1723227309, level='info', message='New fine-tuned model created: ft:davinci-002:personal:davinci-mmlu:9uOQmMSZ', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-EZ9phB97w8n2rliakGZB58HC', created_at=1723227309, level='info', message='Checkpoint created at step 1000 with Snapshot ID: ft:davinci-002:personal:davinci-mmlu:9uOQmN75:ckpt-step-1000', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-0FdaPaT9rnhCfJ6If71SlT4X', created_at=1723227309, level='info', message='Checkpoint created at step 500 with Snapshot ID: ft:davinci-002:personal:davinci-mmlu:9uOQmZP2:ckpt-step-500', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-UE5Av8SqfnGDsXz7UyUCVEH6', created_at=1723227297, level='info', message='Step 1500/1500: training loss=2.13, validation loss=6.57, full validation loss=1.85', object='fine_tuning.job.event', data={'step': 1500, 'train_loss': 2.1291730403900146, 'valid_loss': 6.573358716443162, 'total_steps': 1500, 'full_valid_loss': 1.8481821987725175, 'train_mean_token_accuracy': 0.8333333134651184, 'valid_mean_token_accuracy': 0.3333333333333333, 'full_valid_mean_token_accuracy': 0.746}, type='metrics'), FineTuningJobEvent(id='ftevent-RNqD2Yl7QgNwMJICPPJNKlPX', created_at=1723227281, level='info', message='Step 1499/1500: training loss=0.15', object='fine_tuning.job.event', data={'step': 1499, 'train_loss': 0.15497878193855286, 'total_steps': 1500, 'train_mean_token_accuracy': 0.8333333134651184}, type='metrics'), FineTuningJobEvent(id='ftevent-ZEN2LAZPloAaZH2mUljefSux', created_at=1723227278, level='info', message='Step 1498/1500: training loss=1.55', object='fine_tuning.job.event', data={'step': 1498, 'train_loss': 1.549864649772644, 'total_steps': 1500, 'train_mean_token_accuracy': 0.6666666865348816}, type='metrics'), FineTuningJobEvent(id='ftevent-3piLMx2ddrmzEhckEmxHgCgS', created_at=1723227278, level='info', message='Step 1497/1500: training loss=1.67', object='fine_tuning.job.event', data={'step': 1497, 'train_loss': 1.6695613861083984, 'total_steps': 1500, 'train_mean_token_accuracy': 0.8333333134651184}, type='metrics'), FineTuningJobEvent(id='ftevent-237GH1jV44WluvI2BVcov8Y5', created_at=1723227278, level='info', message='Step 1496/1500: training loss=0.00', object='fine_tuning.job.event', data={'step': 1496, 'train_loss': 0.0005561409634537995, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-wGw4tqM7OEMPfLYJsmaYydCD', created_at=1723227278, level='info', message='Step 1495/1500: training loss=3.38', object='fine_tuning.job.event', data={'step': 1495, 'train_loss': 3.3765909671783447, 'total_steps': 1500, 'train_mean_token_accuracy': 0.6666666865348816}, type='metrics'), FineTuningJobEvent(id='ftevent-983n909i2QzmdfFRtWWGpBpz', created_at=1723227278, level='info', message='Step 1494/1500: training loss=0.13', object='fine_tuning.job.event', data={'step': 1494, 'train_loss': 0.13472110033035278, 'total_steps': 1500, 'train_mean_token_accuracy': 0.8333333134651184}, type='metrics'), FineTuningJobEvent(id='ftevent-vph0t7cjpB5TqaBj62JLj4p0', created_at=1723227278, level='info', message='Step 1493/1500: training loss=0.00', object='fine_tuning.job.event', data={'step': 1493, 'train_loss': 0.002151219407096505, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-fuLj6OofxXr6U091sQfY0ykW', created_at=1723227276, level='info', message='Step 1492/1500: training loss=0.00', object='fine_tuning.job.event', data={'step': 1492, 'train_loss': 6.357822712743655e-07, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-7LI3VqMbQjWDT03dW1S8nGS3', created_at=1723227276, level='info', message='Step 1491/1500: training loss=0.00', object='fine_tuning.job.event', data={'step': 1491, 'train_loss': 0.00037010436062701046, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-eS5pZRVy8Z5TJPhbROLmFd3V', created_at=1723227276, level='info', message='Step 1490/1500: training loss=0.19', object='fine_tuning.job.event', data={'step': 1490, 'train_loss': 0.19141221046447754, 'total_steps': 1500, 'train_mean_token_accuracy': 0.8333333134651184}, type='metrics'), FineTuningJobEvent(id='ftevent-2ToQsUm2OAeCrBJVAO5decX3', created_at=1723227276, level='info', message='Step 1489/1500: training loss=0.00', object='fine_tuning.job.event', data={'step': 1489, 'train_loss': 0.00018964796618092805, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-qOI80zGsfV15qlRV1JIJBWm0', created_at=1723227276, level='info', message='Step 1488/1500: training loss=0.00', object='fine_tuning.job.event', data={'step': 1488, 'train_loss': 0.0002173509419662878, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-5o1HEdGZ4DoCQfv1t6yUym2f', created_at=1723227274, level='info', message='Step 1487/1500: training loss=0.49', object='fine_tuning.job.event', data={'step': 1487, 'train_loss': 0.4881257712841034, 'total_steps': 1500, 'train_mean_token_accuracy': 0.8333333134651184}, type='metrics'), FineTuningJobEvent(id='ftevent-1vxRv74VfNrCIUbERfRKHVKc', created_at=1723227274, level='info', message='Step 1486/1500: training loss=0.22', object='fine_tuning.job.event', data={'step': 1486, 'train_loss': 0.22205598652362823, 'total_steps': 1500, 'train_mean_token_accuracy': 0.8333333134651184}, type='metrics'), FineTuningJobEvent(id='ftevent-mItEgSUUXz5M5rQsXNE6FaS4', created_at=1723227274, level='info', message='Step 1485/1500: training loss=2.23', object='fine_tuning.job.event', data={'step': 1485, 'train_loss': 2.2275490760803223, 'total_steps': 1500, 'train_mean_token_accuracy': 0.8333333134651184}, type='metrics'), FineTuningJobEvent(id='ftevent-r5c92TLYSOjXW7bNXPCYUKHN', created_at=1723227274, level='info', message='Step 1484/1500: training loss=0.95', object='fine_tuning.job.event', data={'step': 1484, 'train_loss': 0.9482726454734802, 'total_steps': 1500, 'train_mean_token_accuracy': 0.6666666865348816}, type='metrics'), FineTuningJobEvent(id='ftevent-LBo4H07LEaBTKb74EMNQYV8T', created_at=1723227274, level='info', message='Step 1483/1500: training loss=3.02', object='fine_tuning.job.event', data={'step': 1483, 'train_loss': 3.018996238708496, 'total_steps': 1500, 'train_mean_token_accuracy': 0.8333333134651184}, type='metrics'), FineTuningJobEvent(id='ftevent-EpxO6Dfzr9AClTwhupYG2kWZ', created_at=1723227273, level='info', message='Step 1482/1500: training loss=0.00', object='fine_tuning.job.event', data={'step': 1482, 'train_loss': 3.437173518250347e-06, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-z6jGnbSCkHXkEbRPdqlHutty', created_at=1723227271, level='info', message='Step 1481/1500: training loss=0.00', object='fine_tuning.job.event', data={'step': 1481, 'train_loss': 2.483514435880352e-06, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-BwEINB6eDoRmjI7zmoGAQoKJ', created_at=1723227271, level='info', message='Step 1480/1500: training loss=0.15', object='fine_tuning.job.event', data={'step': 1480, 'train_loss': 0.15143290162086487, 'total_steps': 1500, 'train_mean_token_accuracy': 0.8333333134651184}, type='metrics'), FineTuningJobEvent(id='ftevent-yNy7imInbnfsVcZEjpEeVqFX', created_at=1723227271, level='info', message='Step 1479/1500: training loss=0.00', object='fine_tuning.job.event', data={'step': 1479, 'train_loss': 4.632647323887795e-05, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-GQH3MNiPJyFvUuaKTun1NaLF', created_at=1723227271, level='info', message='Step 1478/1500: training loss=0.00', object='fine_tuning.job.event', data={'step': 1478, 'train_loss': 3.824233135674149e-05, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-LO9e7Gl8kJg0VmxFMoMLiiIW', created_at=1723227271, level='info', message='Step 1477/1500: training loss=0.10', object='fine_tuning.job.event', data={'step': 1477, 'train_loss': 0.10283421725034714, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-7ZVI2V9okIDtCtSSu45xVjiL', created_at=1723227269, level='info', message='Step 1476/1500: training loss=2.53', object='fine_tuning.job.event', data={'step': 1476, 'train_loss': 2.527172803878784, 'total_steps': 1500, 'train_mean_token_accuracy': 0.6666666865348816}, type='metrics'), FineTuningJobEvent(id='ftevent-lmRjRolbWBPFa6vfSmsKD24Y', created_at=1723227269, level='info', message='Step 1475/1500: training loss=0.00', object='fine_tuning.job.event', data={'step': 1475, 'train_loss': 5.066351604909869e-06, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-t9pmXSuVd1KMG9EmsWzcAoxc', created_at=1723227269, level='info', message='Step 1474/1500: training loss=0.09', object='fine_tuning.job.event', data={'step': 1474, 'train_loss': 0.0860585868358612, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-vczORSsch16crv6iczwEoWEG', created_at=1723227269, level='info', message='Step 1473/1500: training loss=0.00', object='fine_tuning.job.event', data={'step': 1473, 'train_loss': 1.8079990695696324e-06, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-HW2MTc8LnuyTwYimEyfgSp5Y', created_at=1723227269, level='info', message='Step 1472/1500: training loss=0.00', object='fine_tuning.job.event', data={'step': 1472, 'train_loss': 2.185498033213662e-06, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-zlKxUptvPHFHoY04ToRMbh6a', created_at=1723227269, level='info', message='Step 1471/1500: training loss=0.00', object='fine_tuning.job.event', data={'step': 1471, 'train_loss': 6.178939656820148e-06, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-apWTue9LPuJlSu4iQG1hBC8q', created_at=1723227266, level='info', message='Step 1470/1500: training loss=0.24', object='fine_tuning.job.event', data={'step': 1470, 'train_loss': 0.24135583639144897, 'total_steps': 1500, 'train_mean_token_accuracy': 0.8333333134651184}, type='metrics'), FineTuningJobEvent(id='ftevent-lYMmviRvFzhv59n5mLwuCAPr', created_at=1723227266, level='info', message='Step 1469/1500: training loss=0.41', object='fine_tuning.job.event', data={'step': 1469, 'train_loss': 0.413730263710022, 'total_steps': 1500, 'train_mean_token_accuracy': 0.8333333134651184}, type='metrics'), FineTuningJobEvent(id='ftevent-rTI6fwV1IqucbHeircGwqKzo', created_at=1723227266, level='info', message='Step 1468/1500: training loss=0.00', object='fine_tuning.job.event', data={'step': 1468, 'train_loss': 3.5762775496550603e-07, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-Aw0U4XhpCmJavjrZmhVFXKYu', created_at=1723227266, level='info', message='Step 1467/1500: training loss=0.24', object='fine_tuning.job.event', data={'step': 1467, 'train_loss': 0.24127425253391266, 'total_steps': 1500, 'train_mean_token_accuracy': 0.8333333134651184}, type='metrics'), FineTuningJobEvent(id='ftevent-5iD8vtVndSYVdTq4E9q4ey4Q', created_at=1723227264, level='info', message='Step 1466/1500: training loss=0.00', object='fine_tuning.job.event', data={'step': 1466, 'train_loss': 0.00015537755098193884, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-53l17vUwTP7gl89URESihBnz', created_at=1723227264, level='info', message='Step 1465/1500: training loss=0.40', object='fine_tuning.job.event', data={'step': 1465, 'train_loss': 0.39659059047698975, 'total_steps': 1500, 'train_mean_token_accuracy': 0.8333333134651184}, type='metrics'), FineTuningJobEvent(id='ftevent-x9KkvycefjVgRcgj7NtpaMcv', created_at=1723227264, level='info', message='Step 1464/1500: training loss=1.09', object='fine_tuning.job.event', data={'step': 1464, 'train_loss': 1.0915526151657104, 'total_steps': 1500, 'train_mean_token_accuracy': 0.8333333134651184}, type='metrics'), FineTuningJobEvent(id='ftevent-ZfNKqZ2ZXXa41vV6tUaKjotp', created_at=1723227264, level='info', message='Step 1463/1500: training loss=1.66', object='fine_tuning.job.event', data={'step': 1463, 'train_loss': 1.6608604192733765, 'total_steps': 1500, 'train_mean_token_accuracy': 0.6666666865348816}, type='metrics'), FineTuningJobEvent(id='ftevent-X61QelwQ4qsdfm3yDYDdgqXH', created_at=1723227264, level='info', message='Step 1462/1500: training loss=2.06', object='fine_tuning.job.event', data={'step': 1462, 'train_loss': 2.0640451908111572, 'total_steps': 1500, 'train_mean_token_accuracy': 0.8333333134651184}, type='metrics'), FineTuningJobEvent(id='ftevent-RNJJU7Mk6H9OAyZMeuGEX4UZ', created_at=1723227264, level='info', message='Step 1461/1500: training loss=0.18', object='fine_tuning.job.event', data={'step': 1461, 'train_loss': 0.1758470982313156, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-jkWD8Tm8u3BngsCMoPBlhqr8', created_at=1723227262, level='info', message='Step 1460/1500: training loss=0.09', object='fine_tuning.job.event', data={'step': 1460, 'train_loss': 0.08683836460113525, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-JXg9DmLbl4ROMdd6eMvNy7vV', created_at=1723227262, level='info', message='Step 1459/1500: training loss=1.90', object='fine_tuning.job.event', data={'step': 1459, 'train_loss': 1.899632453918457, 'total_steps': 1500, 'train_mean_token_accuracy': 0.5}, type='metrics'), FineTuningJobEvent(id='ftevent-IFIna3crBeVb6ofxXI3uPGFn', created_at=1723227262, level='info', message='Step 1458/1500: training loss=1.43', object='fine_tuning.job.event', data={'step': 1458, 'train_loss': 1.4314624071121216, 'total_steps': 1500, 'train_mean_token_accuracy': 0.8333333134651184}, type='metrics'), FineTuningJobEvent(id='ftevent-2eT6MlFiAnxcKheXPvWpH2am', created_at=1723227262, level='info', message='Step 1457/1500: training loss=0.14', object='fine_tuning.job.event', data={'step': 1457, 'train_loss': 0.14117497205734253, 'total_steps': 1500, 'train_mean_token_accuracy': 0.8333333134651184}, type='metrics'), FineTuningJobEvent(id='ftevent-FmAxUtVvryk1qNMcSY39uZmY', created_at=1723227262, level='info', message='Step 1456/1500: training loss=0.00', object='fine_tuning.job.event', data={'step': 1456, 'train_loss': 1.986821303034958e-07, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-pmYzHDNrfqs4d7ZaAVDdZKFf', created_at=1723227262, level='info', message='Step 1455/1500: training loss=1.33', object='fine_tuning.job.event', data={'step': 1455, 'train_loss': 1.3333630561828613, 'total_steps': 1500, 'train_mean_token_accuracy': 0.8333333134651184}, type='metrics'), FineTuningJobEvent(id='ftevent-OlEZNVBrXD4OcfTZCfuFYEJs', created_at=1723227259, level='info', message='Step 1454/1500: training loss=0.50', object='fine_tuning.job.event', data={'step': 1454, 'train_loss': 0.4994259774684906, 'total_steps': 1500, 'train_mean_token_accuracy': 0.6666666865348816}, type='metrics'), FineTuningJobEvent(id='ftevent-WchCjgfO4GmuBxMq4TJBSOHy', created_at=1723227259, level='info', message='Step 1453/1500: training loss=0.56', object='fine_tuning.job.event', data={'step': 1453, 'train_loss': 0.5556939840316772, 'total_steps': 1500, 'train_mean_token_accuracy': 0.8333333134651184}, type='metrics'), FineTuningJobEvent(id='ftevent-zvXT235Del2pfeoSpeRnSCgv', created_at=1723227259, level='info', message='Step 1452/1500: training loss=0.00', object='fine_tuning.job.event', data={'step': 1452, 'train_loss': 3.5762778338721546e-07, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-2MZ3v3FX0p5sS2crwoYltW9e', created_at=1723227259, level='info', message='Step 1451/1500: training loss=0.01', object='fine_tuning.job.event', data={'step': 1451, 'train_loss': 0.01038710493594408, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-AKj9vpNVeTfL93b55SScj1aU', created_at=1723227259, level='info', message='Step 1450/1500: training loss=0.53', object='fine_tuning.job.event', data={'step': 1450, 'train_loss': 0.5257271528244019, 'total_steps': 1500, 'train_mean_token_accuracy': 0.8333333134651184}, type='metrics'), FineTuningJobEvent(id='ftevent-OuhtX7aiXqEcoBeTSfC9NnVZ', created_at=1723227257, level='info', message='Step 1449/1500: training loss=0.00', object='fine_tuning.job.event', data={'step': 1449, 'train_loss': 0.0009734023478813469, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-NCfh4dVefKUtwh8hWzrJ09fH', created_at=1723227257, level='info', message='Step 1448/1500: training loss=0.14', object='fine_tuning.job.event', data={'step': 1448, 'train_loss': 0.13519924879074097, 'total_steps': 1500, 'train_mean_token_accuracy': 0.8333333134651184}, type='metrics'), FineTuningJobEvent(id='ftevent-wmrgki1sibqb0Zd3oZnENHLs', created_at=1723227257, level='info', message='Step 1447/1500: training loss=0.28', object='fine_tuning.job.event', data={'step': 1447, 'train_loss': 0.2770843207836151, 'total_steps': 1500, 'train_mean_token_accuracy': 0.8333333134651184}, type='metrics'), FineTuningJobEvent(id='ftevent-UcED4c0dtGz7tqiBh4S7W3ju', created_at=1723227257, level='info', message='Step 1446/1500: training loss=0.02', object='fine_tuning.job.event', data={'step': 1446, 'train_loss': 0.024816332384943962, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-7NW0kC6BWSfFajCKjywknGH2', created_at=1723227257, level='info', message='Step 1445/1500: training loss=0.09', object='fine_tuning.job.event', data={'step': 1445, 'train_loss': 0.0925150141119957, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-sX8tLW3XXEdDYy330wWPZa82', created_at=1723227255, level='info', message='Step 1444/1500: training loss=2.01', object='fine_tuning.job.event', data={'step': 1444, 'train_loss': 2.0104188919067383, 'total_steps': 1500, 'train_mean_token_accuracy': 0.5}, type='metrics'), FineTuningJobEvent(id='ftevent-ydJKOU87hWoXxADvoPnQE8Yn', created_at=1723227255, level='info', message='Step 1443/1500: training loss=0.00', object='fine_tuning.job.event', data={'step': 1443, 'train_loss': 0.0008715894655324519, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-EXLe6rgT9EmUWmD6RCoXYAJe', created_at=1723227255, level='info', message='Step 1442/1500: training loss=0.09', object='fine_tuning.job.event', data={'step': 1442, 'train_loss': 0.09461935609579086, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-RGz5yBk8jHyziJrSJmBxDhEf', created_at=1723227255, level='info', message='Step 1441/1500: training loss=1.84', object='fine_tuning.job.event', data={'step': 1441, 'train_loss': 1.8398884534835815, 'total_steps': 1500, 'train_mean_token_accuracy': 0.8333333134651184}, type='metrics'), FineTuningJobEvent(id='ftevent-kFwh1iIOrPPdyHHVMEGKY4ru', created_at=1723227254, level='info', message='Step 1440/1500: training loss=2.31', object='fine_tuning.job.event', data={'step': 1440, 'train_loss': 2.31099796295166, 'total_steps': 1500, 'train_mean_token_accuracy': 0.8333333134651184}, type='metrics'), FineTuningJobEvent(id='ftevent-aY19WyObNm645S4wADYVTguo', created_at=1723227254, level='info', message='Step 1439/1500: training loss=0.38', object='fine_tuning.job.event', data={'step': 1439, 'train_loss': 0.37860536575317383, 'total_steps': 1500, 'train_mean_token_accuracy': 0.8333333134651184}, type='metrics'), FineTuningJobEvent(id='ftevent-fADI3Z3gaUMuxcnmgpdroHcj', created_at=1723227252, level='info', message='Step 1438/1500: training loss=0.00', object='fine_tuning.job.event', data={'step': 1438, 'train_loss': 2.9802316703353426e-07, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-6S9Znu6juuuxS5XGyDMMcGWY', created_at=1723227252, level='info', message='Step 1437/1500: training loss=0.72', object='fine_tuning.job.event', data={'step': 1437, 'train_loss': 0.7163093090057373, 'total_steps': 1500, 'train_mean_token_accuracy': 0.8333333134651184}, type='metrics'), FineTuningJobEvent(id='ftevent-ngqCSQn7y1pZnRozwN8pLykp', created_at=1723227252, level='info', message='Step 1436/1500: training loss=3.70', object='fine_tuning.job.event', data={'step': 1436, 'train_loss': 3.6973273754119873, 'total_steps': 1500, 'train_mean_token_accuracy': 0.5}, type='metrics'), FineTuningJobEvent(id='ftevent-Zpyybvp70l3UGqZSksI0CTVK', created_at=1723227252, level='info', message='Step 1435/1500: training loss=1.48', object='fine_tuning.job.event', data={'step': 1435, 'train_loss': 1.4849432706832886, 'total_steps': 1500, 'train_mean_token_accuracy': 0.6666666865348816}, type='metrics'), FineTuningJobEvent(id='ftevent-qwn1nYeTV6BgQ0vXEZmMVrak', created_at=1723227252, level='info', message='Step 1434/1500: training loss=0.62', object='fine_tuning.job.event', data={'step': 1434, 'train_loss': 0.6244974732398987, 'total_steps': 1500, 'train_mean_token_accuracy': 0.6666666865348816}, type='metrics'), FineTuningJobEvent(id='ftevent-cJPGetSX9Lot3OFOsLkSlA1k', created_at=1723227252, level='info', message='Step 1433/1500: training loss=0.00', object='fine_tuning.job.event', data={'step': 1433, 'train_loss': 8.733808499528095e-05, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-UtIOUeBJdhQB3Vj43YobeH0d', created_at=1723227249, level='info', message='Step 1432/1500: training loss=0.00', object='fine_tuning.job.event', data={'step': 1432, 'train_loss': 0.00018070476653520018, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-Hql26yBynm12KFHHSAZPgcoP', created_at=1723227249, level='info', message='Step 1431/1500: training loss=0.10', object='fine_tuning.job.event', data={'step': 1431, 'train_loss': 0.09883459657430649, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-vSjfShVpAbYs0d2SeQCVFU2f', created_at=1723227249, level='info', message='Step 1430/1500: training loss=0.93', object='fine_tuning.job.event', data={'step': 1430, 'train_loss': 0.930082380771637, 'total_steps': 1500, 'train_mean_token_accuracy': 0.8333333134651184}, type='metrics'), FineTuningJobEvent(id='ftevent-bgIljyBEyVvvj2R5DTykxfyB', created_at=1723227249, level='info', message='Step 1429/1500: training loss=1.80', object='fine_tuning.job.event', data={'step': 1429, 'train_loss': 1.7950092554092407, 'total_steps': 1500, 'train_mean_token_accuracy': 0.5}, type='metrics'), FineTuningJobEvent(id='ftevent-V9dvokedkNoAbcxOdTfol1oH', created_at=1723227249, level='info', message='Step 1428/1500: training loss=0.25', object='fine_tuning.job.event', data={'step': 1428, 'train_loss': 0.25025343894958496, 'total_steps': 1500, 'train_mean_token_accuracy': 0.8333333134651184}, type='metrics'), FineTuningJobEvent(id='ftevent-XZYOYPNlHA3fkHHZxDsQSBPz', created_at=1723227249, level='info', message='Step 1427/1500: training loss=0.00', object='fine_tuning.job.event', data={'step': 1427, 'train_loss': 2.940482090707519e-06, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-Z9sF3NMn8DbsMrjHsd2LWxXb', created_at=1723227247, level='info', message='Step 1426/1500: training loss=0.14', object='fine_tuning.job.event', data={'step': 1426, 'train_loss': 0.13771195709705353, 'total_steps': 1500, 'train_mean_token_accuracy': 0.8333333134651184}, type='metrics'), FineTuningJobEvent(id='ftevent-EO7hbqEYm6bxyeRnLWvVe1s4', created_at=1723227247, level='info', message='Step 1425/1500: training loss=1.73', object='fine_tuning.job.event', data={'step': 1425, 'train_loss': 1.7300281524658203, 'total_steps': 1500, 'train_mean_token_accuracy': 0.8333333134651184}, type='metrics'), FineTuningJobEvent(id='ftevent-4DplzA7FkoqxnchcpeEeHkvR', created_at=1723227247, level='info', message='Step 1424/1500: training loss=0.00', object='fine_tuning.job.event', data={'step': 1424, 'train_loss': 1.0331459634471685e-06, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-Ju51A84vymCfVgl3Dv2lK0y4', created_at=1723227247, level='info', message='Step 1423/1500: training loss=0.15', object='fine_tuning.job.event', data={'step': 1423, 'train_loss': 0.1537310928106308, 'total_steps': 1500, 'train_mean_token_accuracy': 0.8333333134651184}, type='metrics'), FineTuningJobEvent(id='ftevent-oHECzmrfnk8mWuC04GvZOnVq', created_at=1723227247, level='info', message='Step 1422/1500: training loss=0.06', object='fine_tuning.job.event', data={'step': 1422, 'train_loss': 0.062371671199798584, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-18ZFHiFBE2F071QwtPv4pWAu', created_at=1723227247, level='info', message='Step 1421/1500: training loss=0.10', object='fine_tuning.job.event', data={'step': 1421, 'train_loss': 0.10201948136091232, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-rbxYgPf0dxJOOhtiaq8JLn4P', created_at=1723227245, level='info', message='Step 1420/1500: training loss=0.00', object='fine_tuning.job.event', data={'step': 1420, 'train_loss': 0.00015470624202862382, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-tAwdca9RO2WUSLnqvwCcGmV7', created_at=1723227245, level='info', message='Step 1419/1500: training loss=0.39', object='fine_tuning.job.event', data={'step': 1419, 'train_loss': 0.3879108428955078, 'total_steps': 1500, 'train_mean_token_accuracy': 0.6666666865348816}, type='metrics'), FineTuningJobEvent(id='ftevent-UAjooyZsYSck1xxkfO88OMLh', created_at=1723227245, level='info', message='Step 1418/1500: training loss=0.00', object='fine_tuning.job.event', data={'step': 1418, 'train_loss': 0.00010495135211385787, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-aueIfg4q2EtfrA1cZhCAd0Ym', created_at=1723227245, level='info', message='Step 1417/1500: training loss=0.44', object='fine_tuning.job.event', data={'step': 1417, 'train_loss': 0.4363875389099121, 'total_steps': 1500, 'train_mean_token_accuracy': 0.8333333134651184}, type='metrics'), FineTuningJobEvent(id='ftevent-sgVtRoc48LLvlBSObGVc7pKS', created_at=1723227244, level='info', message='Step 1416/1500: training loss=0.00', object='fine_tuning.job.event', data={'step': 1416, 'train_loss': 0.00039316280162893236, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-zjYr98yfo1aU2ARS6TtBsjEL', created_at=1723227242, level='info', message='Step 1415/1500: training loss=0.03', object='fine_tuning.job.event', data={'step': 1415, 'train_loss': 0.02504291944205761, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-3mcIRcSXAqC0jd0vVDi3QgxU', created_at=1723227242, level='info', message='Step 1414/1500: training loss=1.90', object='fine_tuning.job.event', data={'step': 1414, 'train_loss': 1.904676079750061, 'total_steps': 1500, 'train_mean_token_accuracy': 0.8333333134651184}, type='metrics'), FineTuningJobEvent(id='ftevent-LMiA0CjrIZObNFSdrm8BjGSP', created_at=1723227242, level='info', message='Step 1413/1500: training loss=0.47', object='fine_tuning.job.event', data={'step': 1413, 'train_loss': 0.4659511148929596, 'total_steps': 1500, 'train_mean_token_accuracy': 0.6666666865348816}, type='metrics'), FineTuningJobEvent(id='ftevent-Bt6hbQe3kWnah71JOyVBmLAL', created_at=1723227242, level='info', message='Step 1412/1500: training loss=0.00', object='fine_tuning.job.event', data={'step': 1412, 'train_loss': 7.053103672660654e-06, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-qv0yX8ohDJ6tFtna2HertTa0', created_at=1723227242, level='info', message='Step 1411/1500: training loss=0.13', object='fine_tuning.job.event', data={'step': 1411, 'train_loss': 0.12880657613277435, 'total_steps': 1500, 'train_mean_token_accuracy': 0.8333333134651184}, type='metrics'), FineTuningJobEvent(id='ftevent-SeffhKlPorPG2hPcjI3bu0QP', created_at=1723227240, level='info', message='Step 1410/1500: training loss=1.48', object='fine_tuning.job.event', data={'step': 1410, 'train_loss': 1.4805246591567993, 'total_steps': 1500, 'train_mean_token_accuracy': 0.8333333134651184}, type='metrics'), FineTuningJobEvent(id='ftevent-GcbMAuV4siorJ4maR7ixW31F', created_at=1723227240, level='info', message='Step 1409/1500: training loss=0.09', object='fine_tuning.job.event', data={'step': 1409, 'train_loss': 0.09175906330347061, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-6ZgSKuA0rIfWyQDhPauyrEMl', created_at=1723227240, level='info', message='Step 1408/1500: training loss=0.00', object='fine_tuning.job.event', data={'step': 1408, 'train_loss': 2.3841853646899835e-07, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-INgrXi5Ix3FNR5HNVUuUA1FO', created_at=1723227240, level='info', message='Step 1407/1500: training loss=0.10', object='fine_tuning.job.event', data={'step': 1407, 'train_loss': 0.09585227817296982, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-3FF1eaEriexJchcdXxQhAbvr', created_at=1723227240, level='info', message='Step 1406/1500: training loss=0.00', object='fine_tuning.job.event', data={'step': 1406, 'train_loss': 0.0002083133877022192, 'total_steps': 1500, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-FthraiYRw2Cwi0L9oZgJMzFB', created_at=1723227240, level='info', message='Step 1405/1500: training loss=1.62', object='fine_tuning.job.event', data={'step': 1405, 'train_loss': 1.6164480447769165, 'total_steps': 1500, 'train_mean_token_accuracy': 0.8333333134651184}, type='metrics')], object='list', has_more=True)\n"
     ]
    }
   ],
   "source": [
    "print(client.fine_tuning.jobs.list_events(fine_tuning_job_id=\"ftjob-qNsCRUUZU726tnqnTqncnrPs\", limit=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do inference on, train, val, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 0 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Batch 0 done\n",
      "Processing batch 100 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Absolutely'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Absolutely'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 100 done\n",
      "Processing batch 200 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' None'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Batch 200 done\n",
      "Processing batch 300 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Batch 300 done\n",
      "Processing batch 400 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Absolutely'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Batch 400 done\n",
      "Processing batch 500 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Batch 500 done\n",
      "Processing batch 600 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 600 done\n",
      "Processing batch 700 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Batch 700 done\n",
      "Processing batch 800 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' no'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 800 done\n",
      "Processing batch 900 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Batch 900 done\n",
      "Processing batch 1000 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 1000 done\n",
      "Processing batch 1100 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Batch 1100 done\n",
      "Processing batch 1200 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 1200 done\n",
      "Processing batch 1300 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Batch 1300 done\n",
      "Processing batch 1400 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Absolutely'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 1400 done\n",
      "Processing batch 1500 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 1500 done\n",
      "Processing batch 1600 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Batch 1600 done\n",
      "Processing batch 1700 of 143\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' N'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 1700 done\n",
      "Processing batch 1800 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 1800 done\n",
      "Processing batch 1900 of 143\n",
      "Warning: logprobs keys are dict_keys([' No', ' no'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' no'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Absolutely'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Absolutely'])\n",
      "Batch 1900 done\n",
      "Processing batch 2000 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Batch 2000 done\n",
      "Processing batch 2100 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' N'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Batch 2100 done\n",
      "Processing batch 2200 of 143\n",
      "Warning: logprobs keys are dict_keys([' No', ' no'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 2200 done\n",
      "Processing batch 2300 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 2300 done\n",
      "Processing batch 2400 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Batch 2400 done\n",
      "Processing batch 2500 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 2500 done\n",
      "Processing batch 2600 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Absolutely'])\n",
      "Batch 2600 done\n",
      "Processing batch 2700 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 2700 done\n",
      "Processing batch 2800 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Batch 2800 done\n",
      "Processing batch 2900 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 2900 done\n",
      "Processing batch 3000 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Batch 3000 done\n",
      "Processing batch 3100 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' no'])\n",
      "Batch 3100 done\n",
      "Processing batch 3200 of 143\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' no'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 3200 done\n",
      "Processing batch 3300 of 143\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' no'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Absolutely'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Absolutely'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Batch 3300 done\n",
      "Processing batch 3400 of 143\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Absolutely'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Batch 3400 done\n",
      "Processing batch 3500 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' no'])\n",
      "Batch 3500 done\n",
      "Processing batch 3600 of 143\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' None'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Batch 3600 done\n",
      "Processing batch 3700 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Absolutely'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Batch 3700 done\n",
      "Processing batch 3800 of 143\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 3800 done\n",
      "Processing batch 3900 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 3900 done\n",
      "Processing batch 4000 of 143\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Batch 4000 done\n",
      "Processing batch 4100 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' no'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' no'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Batch 4100 done\n",
      "Processing batch 4200 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Batch 4200 done\n",
      "Processing batch 4300 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' no'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 4300 done\n",
      "Processing batch 4400 of 143\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 4400 done\n",
      "Processing batch 4500 of 143\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' no'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Batch 4500 done\n",
      "Processing batch 4600 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 4600 done\n",
      "Processing batch 4700 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 4700 done\n",
      "Processing batch 4800 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Absolutely'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' None'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' N'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Batch 4800 done\n",
      "Processing batch 4900 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' no'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Batch 4900 done\n",
      "Processing batch 5000 of 143\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 5000 done\n",
      "Processing batch 5100 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 5100 done\n",
      "Processing batch 5200 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 5200 done\n",
      "Processing batch 5300 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Batch 5300 done\n",
      "Processing batch 5400 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' N'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Batch 5400 done\n",
      "Processing batch 5500 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' N'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' N'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 5500 done\n",
      "Processing batch 5600 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 5600 done\n",
      "Processing batch 5700 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 5700 done\n",
      "Processing batch 5800 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' no'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' N'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Absolutely'])\n",
      "Batch 5800 done\n",
      "Processing batch 5900 of 143\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Absolutely'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' no'])\n",
      "Batch 5900 done\n",
      "Processing batch 6000 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Batch 6000 done\n",
      "Processing batch 6100 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Batch 6100 done\n",
      "Processing batch 6200 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' no'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Batch 6200 done\n",
      "Processing batch 6300 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Batch 6300 done\n",
      "Processing batch 6400 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 6400 done\n",
      "Processing batch 6500 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 6500 done\n",
      "Processing batch 6600 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Absolutely'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' N'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Batch 6600 done\n",
      "Processing batch 6700 of 143\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Batch 6700 done\n",
      "Processing batch 6800 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Absolutely'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Batch 6800 done\n",
      "Processing batch 6900 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' no'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Batch 6900 done\n",
      "Processing batch 7000 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Batch 7000 done\n",
      "Processing batch 7100 of 143\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 7100 done\n",
      "Processing batch 7200 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Batch 7200 done\n",
      "Processing batch 7300 of 143\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' YES'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 7300 done\n",
      "Processing batch 7400 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' None'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Batch 7400 done\n",
      "Processing batch 7500 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' None'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Batch 7500 done\n",
      "Processing batch 7600 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Absolutely'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Batch 7600 done\n",
      "Processing batch 7700 of 143\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' N'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 7700 done\n",
      "Processing batch 7800 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Batch 7800 done\n",
      "Processing batch 7900 of 143\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Absolutely'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Absolutely'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Batch 7900 done\n",
      "Processing batch 8000 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' yes'])\n",
      "Batch 8000 done\n",
      "Processing batch 8100 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 8100 done\n",
      "Processing batch 8200 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Batch 8200 done\n",
      "Processing batch 8300 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Batch 8300 done\n",
      "Processing batch 8400 of 143\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Absolutely'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Batch 8400 done\n",
      "Processing batch 8500 of 143\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Absolutely'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Batch 8500 done\n",
      "Processing batch 8600 of 143\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' N'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Batch 8600 done\n",
      "Processing batch 8700 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 8700 done\n",
      "Processing batch 8800 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Batch 8800 done\n",
      "Processing batch 8900 of 143\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Batch 8900 done\n",
      "Processing batch 9000 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 9000 done\n",
      "Processing batch 9100 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Absolutely'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 9100 done\n",
      "Processing batch 9200 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Absolutely'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' N'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 9200 done\n",
      "Processing batch 9300 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 9300 done\n",
      "Processing batch 9400 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Batch 9400 done\n",
      "Processing batch 9500 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Batch 9500 done\n",
      "Processing batch 9600 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Absolutely'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 9600 done\n",
      "Processing batch 9700 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Batch 9700 done\n",
      "Processing batch 9800 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' no'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Batch 9800 done\n",
      "Processing batch 9900 of 143\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Absolutely'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Batch 9900 done\n",
      "Processing batch 10000 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 10000 done\n",
      "Processing batch 10100 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' no'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Absolutely'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 10100 done\n",
      "Processing batch 10200 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Batch 10200 done\n",
      "Processing batch 10300 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' no'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Batch 10300 done\n",
      "Processing batch 10400 of 143\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' no'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Batch 10400 done\n",
      "Processing batch 10500 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 10500 done\n",
      "Processing batch 10600 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Absolutely'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Batch 10600 done\n",
      "Processing batch 10700 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Batch 10700 done\n",
      "Processing batch 10800 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Batch 10800 done\n",
      "Processing batch 10900 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Absolutely'])\n",
      "Batch 10900 done\n",
      "Processing batch 11000 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 11000 done\n",
      "Processing batch 11100 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Absolutely'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Batch 11100 done\n",
      "Processing batch 11200 of 143\n",
      "Warning: logprobs keys are dict_keys([' No', ' N'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' no'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Batch 11200 done\n",
      "Processing batch 11300 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Batch 11300 done\n",
      "Processing batch 11400 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 11400 done\n",
      "Processing batch 11500 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 11500 done\n",
      "Processing batch 11600 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Absolutely'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 11600 done\n",
      "Processing batch 11700 of 143\n",
      "Warning: logprobs keys are dict_keys([' No', ' N'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' no'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Batch 11700 done\n",
      "Processing batch 11800 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Batch 11800 done\n",
      "Processing batch 11900 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Batch 11900 done\n",
      "Processing batch 12000 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Batch 12000 done\n",
      "Processing batch 12100 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 12100 done\n",
      "Processing batch 12200 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Batch 12200 done\n",
      "Processing batch 12300 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 12300 done\n",
      "Processing batch 12400 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Absolutely'])\n",
      "Batch 12400 done\n",
      "Processing batch 12500 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' no'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' None'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 12500 done\n",
      "Processing batch 12600 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' None'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' None'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Batch 12600 done\n",
      "Processing batch 12700 of 143\n",
      "Warning: logprobs keys are dict_keys([' No', ' no'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' N'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 12700 done\n",
      "Processing batch 12800 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 12800 done\n",
      "Processing batch 12900 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Batch 12900 done\n",
      "Processing batch 13000 of 143\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Absolutely'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' no'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Absolutely'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' None'])\n",
      "Batch 13000 done\n",
      "Processing batch 13100 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 13100 done\n",
      "Processing batch 13200 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Batch 13200 done\n",
      "Processing batch 13300 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' N'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' no'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' N'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Batch 13300 done\n",
      "Processing batch 13400 of 143\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' no'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Batch 13400 done\n",
      "Processing batch 13500 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Batch 13500 done\n",
      "Processing batch 13600 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' no'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 13600 done\n",
      "Processing batch 13700 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Batch 13700 done\n",
      "Processing batch 13800 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Absolutely'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Batch 13800 done\n",
      "Processing batch 13900 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Absolutely'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Batch 13900 done\n",
      "Processing batch 14000 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Batch 14000 done\n",
      "Processing batch 14100 of 143\n",
      "Warning: logprobs keys are dict_keys([' No', ' N'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', 'No'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' no'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' NO'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' N'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Batch 14100 done\n",
      "Processing batch 14200 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' No', ' N'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Absolutely'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Batch 14200 done\n",
      "Processing batch 14300 of 143\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Indeed'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', 'Yes'])\n",
      "Warning: logprobs keys are dict_keys([' Yes', ' Y'])\n",
      "Batch 14300 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flattening the indices: 100%|| 14358/14358 [00:01<00:00, 8283.63 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from openai import AsyncOpenAI\n",
    "import asyncio\n",
    "\n",
    "\n",
    "client = AsyncOpenAI(api_key=key)\n",
    "\n",
    "async def completions_inference(row, model_id, num_tries=5):\n",
    "    for _ in range(num_tries):\n",
    "        try:\n",
    "            resp = await client.completions.create(\n",
    "                model=model_id,\n",
    "                prompt=row[\"completion\"][\"prompt\"],\n",
    "                temperature=0.0,\n",
    "                max_tokens=1,\n",
    "                top_p=1.0,\n",
    "                frequency_penalty=0.0,\n",
    "                presence_penalty=0.0,\n",
    "                logprobs=2,\n",
    "            )\n",
    "            logrpobs = resp.choices[0].logprobs.top_logprobs[0]\n",
    "            if set(logrpobs.keys()) != {\" Yes\", \" No\"}:\n",
    "                print(f\"Warning: logprobs keys are {logrpobs.keys()}\")\n",
    "            \n",
    "            \n",
    "            p = np.exp(logrpobs.get(\" Yes\", -100)) / (np.exp(logrpobs.get(\" Yes\", -100)) + np.exp(logrpobs.get(\" No\", -100)))\n",
    "            return p\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            await asyncio.sleep(15)\n",
    "            continue\n",
    "\n",
    "weak_model_id = \"ft:davinci-002:personal:davinci-mmlu:9uOQmMSZ\"\n",
    "split_name = \"train\"\n",
    "batch_size = 100\n",
    "split_ps_all = []\n",
    "for i in range(0, len(splits[split_name]), batch_size):\n",
    "    print(f\"Processing batch {i//batch_size} of {len(splits[split_name])//batch_size}\")\n",
    "    end = min(i + batch_size, len(splits[split_name]))\n",
    "    split_ps = await asyncio.gather(*[completions_inference(row, weak_model_id) for row in splits[split_name].select(range(i, end))])\n",
    "    print(f\"Batch {i//batch_size} done\")\n",
    "    await asyncio.sleep(10)\n",
    "    split_ps_all.extend(split_ps)\n",
    "splits[split_name] = splits[split_name].add_column(\"weak_prob\", split_ps_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|| 14358/14358 [00:00<00:00, 650519.22 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'subject', 'choices', 'answer', 'id', 'messages', 'completion', 'hard_label', 'weak_prob'],\n",
       "    num_rows: 14358\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[split_name].save_to_disk(f\"openai/weak_{split_name}\")\n",
    "splits[split_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train 4o on weak labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this step use openai_weak_sft.py instead, to do keep trying requests until there is no more rate limit error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(160, 0),\n",
       " (2440, 12),\n",
       " (1280, 128),\n",
       " (130, 243),\n",
       " (10240, 0),\n",
       " (0, 1024),\n",
       " (40, 60),\n",
       " (9730, 51),\n",
       " (10, 15),\n",
       " (0, 4096),\n",
       " (40960, 0),\n",
       " (20480, 2048),\n",
       " (38920, 204),\n",
       " (0, 16),\n",
       " (2560, 0),\n",
       " (0, 8192),\n",
       " (80, 8),\n",
       " (5120, 512),\n",
       " (610, 3),\n",
       " (0, 64),\n",
       " (320, 32),\n",
       " (640, 0),\n",
       " (0, 256),\n",
       " (2050, 3891),\n",
       " (520, 972)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weak_marginal_costs = [1 / 10]\n",
    "oracle_spending_fracs = [0.0, 0.05, 0.5, 0.95, 1.0]\n",
    "oracle_affordables = [16, 64, 256, 1024, 4096]\n",
    "\n",
    "pairs = []\n",
    "for weak_marginal_cost in weak_marginal_costs:\n",
    "    for oracle_affordable in oracle_affordables:\n",
    "        accs = []\n",
    "        actual_osfs = []\n",
    "        for osf in oracle_spending_fracs:\n",
    "            n_oracle = int(osf * oracle_affordable)\n",
    "            n_weak = int(\n",
    "                (oracle_affordable - n_oracle) / weak_marginal_cost\n",
    "            )\n",
    "            n_oracle = min(n_oracle, 23_000)\n",
    "            pairs.append((n_weak, n_oracle))\n",
    "pairs.append((0, 8192))\n",
    "pairs = list(set(pairs))\n",
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "def upload_files(is_weak, num_weak, num_oracle, num_test, source_dict):\n",
    "    weak_oracle = \"weak\" if is_weak else \"oracle\"\n",
    "    name = f\"{num_weak}-{num_oracle}-{weak_oracle}\"\n",
    "    shuffled_train = source_dict[\"train\"].shuffle(seed=0)\n",
    "    weak = shuffled_train.select(range(num_weak))\n",
    "    oracle = shuffled_train.select(range(num_weak, num_weak + num_oracle))\n",
    "    train = weak if is_weak else oracle\n",
    "    if is_weak:\n",
    "        train = train.add_column(\"label\", (np.array(train[\"weak_prob\"]) > 0.5).astype(int).tolist())  # type: ignore\n",
    "    else:\n",
    "        train = train.add_column(\"label\", train[\"hard_label\"])  # type: ignore\n",
    "\n",
    "    def modify_messages(ex, mes_choices=[\"No\", \"Yes\"], compl_choices=[\" No\", \" Yes\"]):\n",
    "        \"\"\"\n",
    "        Modify the messages to have the requested label\n",
    "        \"\"\"\n",
    "        label = mes_choices[ex[\"label\"]]\n",
    "        mes = ex[\"messages\"][\"messages\"][-1]\n",
    "        assert mes[\"role\"] == \"assistant\"\n",
    "        assert mes[\"content\"] in mes_choices\n",
    "        mes[\"content\"] = label\n",
    "        ex[\"completion\"][\"completion\"] = compl_choices[ex[\"label\"]]\n",
    "        return ex\n",
    "\n",
    "    train = train.map(modify_messages)\n",
    "\n",
    "    test = source_dict[\"test\"].shuffle(seed=0).select(range(num_test))\n",
    "\n",
    "    os.makedirs(f\"openai/{name}\", exist_ok=True)\n",
    "    with open(f\"openai/{name}/{weak_oracle}_train.jsonl\", \"w\") as f:\n",
    "        f.write(\"\\n\".join([json.dumps(d) for d in train[\"messages\"]]))\n",
    "    with open(f\"openai/{name}/{weak_oracle}_test.jsonl\", \"w\") as f:\n",
    "        f.write(\"\\n\".join([json.dumps(d) for d in test[\"messages\"]]))\n",
    "\n",
    "    train_file = client.files.create(\n",
    "        file=open(f\"openai/{name}/{weak_oracle}_train.jsonl\", \"rb\"),\n",
    "        purpose=\"fine-tune\"\n",
    "    )\n",
    "    test_file = client.files.create(\n",
    "        file=open(f\"openai/{name}/{weak_oracle}_test.jsonl\", \"rb\"),\n",
    "        purpose=\"fine-tune\"\n",
    "    )\n",
    "    return train_file, test_file, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict, concatenate_datasets, load_from_disk\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "\n",
    "num_test = 1000\n",
    "\n",
    "splits = dict()\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    splits[split] = load_from_disk(f\"openai/weak_{split}\")\n",
    "weak_dict = DatasetDict({\n",
    "    \"train\": concatenate_datasets([splits[\"train\"], splits[\"val\"]]).shuffle(seed=0),\n",
    "    \"test\": splits[\"test\"],\n",
    "})\n",
    "\n",
    "client = OpenAI(api_key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flattening the indices: 100%|| 160/160 [00:00<00:00, 22149.60 examples/s]\n",
      "Map: 100%|| 160/160 [00:00<00:00, 7553.14 examples/s]\n",
      "Flattening the indices: 100%|| 2440/2440 [00:00<00:00, 11807.44 examples/s]\n",
      "Map: 100%|| 2440/2440 [00:00<00:00, 8112.87 examples/s]\n",
      "Flattening the indices: 100%|| 1280/1280 [00:00<00:00, 24890.40 examples/s]\n",
      "Map: 100%|| 1280/1280 [00:00<00:00, 9790.68 examples/s] \n",
      "Flattening the indices: 100%|| 130/130 [00:00<00:00, 21455.93 examples/s]\n",
      "Map: 100%|| 130/130 [00:00<00:00, 7311.07 examples/s]\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': \"This fine-tune request has been rate-limited. Your organization has reached the maximum of 3 active requests (0 running, 3 pending) for the model 'gpt-4o-mini-2024-07-18'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'rate_limit_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m      5\u001b[0m train_file, test_file, name \u001b[38;5;241m=\u001b[39m upload_files(\u001b[38;5;28;01mTrue\u001b[39;00m, num_weak, num_oracle, num_test, weak_dict)\n\u001b[0;32m----> 6\u001b[0m job \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfine_tuning\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjobs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4o-mini-2024-07-18\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintegrations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwandb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwandb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mproject\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mopenai-sft\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m job_id \u001b[38;5;241m=\u001b[39m job\u001b[38;5;241m.\u001b[39mid\n\u001b[1;32m     14\u001b[0m jobs[name] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob\u001b[39m\u001b[38;5;124m\"\u001b[39m: json\u001b[38;5;241m.\u001b[39mloads(job\u001b[38;5;241m.\u001b[39mmodel_dump_json()),\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_file_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: train_file\u001b[38;5;241m.\u001b[39mid,\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_file_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: test_file\u001b[38;5;241m.\u001b[39mid,\n\u001b[1;32m     18\u001b[0m }\n",
      "File \u001b[0;32m~/.conda/envs/w2s2/lib/python3.12/site-packages/openai/resources/fine_tuning/jobs/jobs.py:133\u001b[0m, in \u001b[0;36mJobs.create\u001b[0;34m(self, model, training_file, hyperparameters, integrations, seed, suffix, validation_file, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m     68\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FineTuningJob:\n\u001b[1;32m     69\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    Creates a fine-tuning job which begins the process of creating a new model from\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    a given dataset.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/fine_tuning/jobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_file\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhyperparameters\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mintegrations\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mintegrations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msuffix\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalidation_file\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjob_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mJobCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFineTuningJob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/w2s2/lib/python3.12/site-packages/openai/_base_client.py:1259\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1246\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1247\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1254\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1255\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1256\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1257\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1258\u001b[0m     )\n\u001b[0;32m-> 1259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.conda/envs/w2s2/lib/python3.12/site-packages/openai/_base_client.py:936\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    928\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    929\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    934\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    935\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 936\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/w2s2/lib/python3.12/site-packages/openai/_base_client.py:1025\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1024\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/.conda/envs/w2s2/lib/python3.12/site-packages/openai/_base_client.py:1074\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1074\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1075\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/w2s2/lib/python3.12/site-packages/openai/_base_client.py:1025\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1024\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/.conda/envs/w2s2/lib/python3.12/site-packages/openai/_base_client.py:1074\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1074\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1075\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/w2s2/lib/python3.12/site-packages/openai/_base_client.py:1040\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1037\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1039\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1040\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1043\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1044\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1048\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39mget_max_retries(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries) \u001b[38;5;241m-\u001b[39m retries,\n\u001b[1;32m   1049\u001b[0m )\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': \"This fine-tune request has been rate-limited. Your organization has reached the maximum of 3 active requests (0 running, 3 pending) for the model 'gpt-4o-mini-2024-07-18'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'rate_limit_exceeded'}}"
     ]
    }
   ],
   "source": [
    "from openai import RateLimitError\n",
    "import time\n",
    "\n",
    "with open(\"openai/jobs.json\", \"r\") as f:\n",
    "    jobs = json.load(f)\n",
    "for num_weak, num_oracle in pairs:\n",
    "    if num_weak == 0:\n",
    "        continue\n",
    "    if f\"{num_weak}-{num_oracle}-weak\" in jobs:\n",
    "        continue\n",
    "    train_file, test_file, name = upload_files(True, num_weak, num_oracle, num_test, weak_dict)\n",
    "    while True:\n",
    "        try:\n",
    "            job = client.fine_tuning.jobs.create(\n",
    "                training_file=train_file.id,\n",
    "                validation_file=test_file.id,\n",
    "                model=\"gpt-4o-mini-2024-07-18\",\n",
    "                suffix=name,\n",
    "                integrations=[{\"type\": \"wandb\", \"wandb\": {\"project\": \"openai-sft\"}}]\n",
    "            )\n",
    "            job_id = job.id\n",
    "            jobs[name] = {\n",
    "                \"job\": json.loads(job.model_dump_json()),\n",
    "                \"train_file_id\": train_file.id,\n",
    "                \"val_file_id\": test_file.id,\n",
    "            }\n",
    "            break\n",
    "        except RateLimitError as e:\n",
    "            print(f\"Rate limit error at {time.time()}\")\n",
    "            time.sleep(120)\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            \n",
    "            time.sleep(120)\n",
    "            continue\n",
    "    with open(\"openai/jobs.json\", \"w\") as f:\n",
    "        f.write(json.dumps(jobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "job_id = \"ftjob-OyNVI9Se55CsMXf2DjzwWxSY\"\n",
    "while True:\n",
    "    status = client.fine_tuning.jobs.retrieve(\"ftjob-OyNVI9Se55CsMXf2DjzwWxSY\").status\n",
    "    if status == \"succeeded\":\n",
    "        break\n",
    "    elif status in [\"failed\", \"cancelled\"]:\n",
    "        raise Exception(f\"Job {job_id} failed with status {status}\")\n",
    "    time.sleep(10)\n",
    "intermediate_model = client.fine_tuning.jobs.retrieve(fine_tuning_job_id=job_id).fine_tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "416"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_events = [e for e in events if e.type == \"metrics\" and \"full_valid_mean_token_accuracy\" in e.data]\n",
    "best_event = max(checkpoint_events, key=lambda x: x.data[\"full_valid_mean_token_accuracy\"])\n",
    "best_step = best_event.data[\"step\"]\n",
    "best_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'object': 'list', 'data': [{'object': 'fine_tuning.job.checkpoint', 'id': 'ftckpt_Qt335bmw9mdMO8bPzWLWKs3I', 'created_at': 1723313453, 'fine_tuned_model_checkpoint': 'ft:gpt-4o-mini-2024-07-18:personal:520-972:9ukr4Nd7', 'fine_tuning_job_id': 'ftjob-OyNVI9Se55CsMXf2DjzwWxSY', 'metrics': {'step': 1248, 'train_loss': 0.00012715657067019492, 'train_mean_token_accuracy': 1.0}, 'step_number': 1248}, {'object': 'fine_tuning.job.checkpoint', 'id': 'ftckpt_6foiSRNnyaAkzUjrXNQYvNod', 'created_at': 1723312926, 'fine_tuned_model_checkpoint': 'ft:gpt-4o-mini-2024-07-18:personal:520-972:9ukr4E6S:ckpt-step-832', 'fine_tuning_job_id': 'ftjob-OyNVI9Se55CsMXf2DjzwWxSY', 'metrics': {'step': 832, 'train_loss': 0.0016434987774118781, 'train_mean_token_accuracy': 1.0}, 'step_number': 832}, {'object': 'fine_tuning.job.checkpoint', 'id': 'ftckpt_Tn68bRzm4XEL9Dh9V0zRKLXQ', 'created_at': 1723312386, 'fine_tuned_model_checkpoint': 'ft:gpt-4o-mini-2024-07-18:personal:520-972:9ukr30LM:ckpt-step-416', 'fine_tuning_job_id': 'ftjob-OyNVI9Se55CsMXf2DjzwWxSY', 'metrics': {'step': 416, 'train_loss': 0.0057195029221475124, 'train_mean_token_accuracy': 1.0}, 'step_number': 416}], 'has_more': False, 'first_id': 'ftckpt_Qt335bmw9mdMO8bPzWLWKs3I', 'last_id': 'ftckpt_Tn68bRzm4XEL9Dh9V0zRKLXQ'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ft:gpt-4o-mini-2024-07-18:personal:520-972:9ukr30LM:ckpt-step-416'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get(f\"https://api.openai.com/v1/fine_tuning/jobs/{job_id}/checkpoints?step={best_step}\", headers={\"Authorization\": f\"Bearer {key}\"})\n",
    "print(response.json())\n",
    "best_checkpoint = [obj[\"fine_tuned_model_checkpoint\"] for obj in response.json()[\"data\"] if obj[\"step_number\"] == best_step][0]\n",
    "best_checkpoint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now do oracle training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle_train_file, oracle_val_file, name = upload_files(False, num_weak, num_oracle, weak_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = client.fine_tuning.jobs.create(\n",
    "    training_file=train_file.id,\n",
    "    validation_file=val_file.id,\n",
    "    model=\"ft:gpt-4o-mini-2024-07-18:personal:520-972:9ukr4Nd7\", #best_checkpoint,\n",
    "    suffix=name,\n",
    "    integrations=[{\"type\": \"wandb\", \"wandb\": {\"project\": \"openai-sft\"}}]\n",
    ")\n",
    "job_id = job.id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FineTuningJobEvent(id='ftevent-IVEuA8CfV3pwfoSAG2w0MiNC', created_at=1723417884, level='info', message='Step 1556/2334: training loss=0.00, full validation loss=0.65', object='fine_tuning.job.event', data={'step': 1556, 'train_loss': 0.00031216940260492265, 'total_steps': 2334, 'full_valid_loss': 0.647935629710299, 'train_mean_token_accuracy': 1.0, 'full_valid_mean_token_accuracy': 0.9123711340206185}, type='metrics'),\n",
       " FineTuningJobEvent(id='ftevent-zE0F3XTolHRkGBXLVAneyOKy', created_at=1723416938, level='info', message='Step 778/2334: training loss=0.00, full validation loss=0.44', object='fine_tuning.job.event', data={'step': 778, 'train_loss': 0.0027147929649800062, 'total_steps': 2334, 'full_valid_loss': 0.43753366044296843, 'train_mean_token_accuracy': 1.0, 'full_valid_mean_token_accuracy': 0.9312714776632303}, type='metrics')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events = client.fine_tuning.jobs.list_events(fine_tuning_job_id=\"ftjob-MeiOEIOVCHaJA1w8ukUgqDv1\", limit=100)\n",
    "checkpoint_events = [e for e in events if e.type == \"metrics\" and \"full_valid_mean_token_accuracy\" in e.data]\n",
    "checkpoint_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'ftjob-wTTXu4HEhFKZ2WQ7U1zdvOCB',\n",
       " 'created_at': 1723420121,\n",
       " 'error': {'code': None, 'message': None, 'param': None},\n",
       " 'fine_tuned_model': None,\n",
       " 'finished_at': None,\n",
       " 'hyperparameters': {'n_epochs': 'auto',\n",
       "  'batch_size': 'auto',\n",
       "  'learning_rate_multiplier': 'auto'},\n",
       " 'model': 'gpt-4o-mini-2024-07-18',\n",
       " 'object': 'fine_tuning.job',\n",
       " 'organization_id': 'org-5KzWCdbJZtVYV7zk2r3Ekq9H',\n",
       " 'result_files': [],\n",
       " 'seed': 1654820938,\n",
       " 'status': 'validating_files',\n",
       " 'trained_tokens': None,\n",
       " 'training_file': 'file-xpxSP83JHNhxk3G2YPNo5oO9',\n",
       " 'validation_file': 'file-C1AUWuwqZZE4a3MuyCjvY0k2',\n",
       " 'estimated_finish': None,\n",
       " 'integrations': [{'type': 'wandb',\n",
       "   'wandb': {'project': 'openai-sft',\n",
       "    'entity': None,\n",
       "    'name': None,\n",
       "    'tags': None,\n",
       "    'run_id': 'ftjob-wTTXu4HEhFKZ2WQ7U1zdvOCB'}}],\n",
       " 'user_provided_suffix': '1280-128-weak'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events = client.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id, limit=100)\n",
    "final_acc = [e for e in events if e.type == \"metrics\" and \"full_valid_mean_token_accuracy\" in e.data][0].data[\"full_valid_mean_token_accuracy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160-0-weak: succeeded\n",
      "2440-12-weak: succeeded\n",
      "1280-128-weak: succeeded\n",
      "130-243-weak: succeeded\n",
      "10240-0-weak: succeeded\n",
      "40-60-weak: succeeded\n",
      "9730-51-weak: succeeded\n",
      "10-15-weak: succeeded\n",
      "2560-0-weak: succeeded\n",
      "160-0-oracle: succeeded\n",
      "2440-12-oracle: succeeded\n",
      "1280-128-oracle: succeeded\n",
      "130-243-oracle: succeeded\n",
      "10240-0-oracle: succeeded\n",
      "0-1024-oracle: succeeded\n",
      "40-60-oracle: succeeded\n",
      "9730-51-oracle: succeeded\n",
      "10-15-oracle: succeeded\n",
      "0-4096-oracle: succeeded\n",
      "0-16-oracle: succeeded\n",
      "2560-0-oracle: succeeded\n",
      "0-8192-oracle: running\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': '160-0-weak',\n",
       "  'job': FineTuningJob(id='ftjob-VrKEiEMvcU8zEIkOS8OgTCbB', created_at=1723420111, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:160-0-weak:9vCrKxJH', finished_at=1723421152, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-5KzWCdbJZtVYV7zk2r3Ekq9H', result_files=['file-Hf306ES5JGvPZ4VXIzAhAf10'], seed=1178864727, status='succeeded', trained_tokens=55092, training_file='file-lDqwvokl7PFqLaQUCysvooSC', validation_file='file-3vax98DB89wuM1rmPmlNbb8N', estimated_finish=None, integrations=[FineTuningJobWandbIntegrationObject(type='wandb', wandb=FineTuningJobWandbIntegration(project='openai-sft', entity=None, name=None, tags=None, run_id='ftjob-VrKEiEMvcU8zEIkOS8OgTCbB'))], user_provided_suffix='160-0-weak'),\n",
       "  'final_acc': 0.9156666666666666},\n",
       " {'name': '2440-12-weak',\n",
       "  'job': FineTuningJob(id='ftjob-8DCNlNyWerNh9zKy8U7F24Oj', created_at=1723420117, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:2440-12-weak:9vDKhTzx', finished_at=1723422973, hyperparameters=Hyperparameters(n_epochs=3, batch_size=4, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-5KzWCdbJZtVYV7zk2r3Ekq9H', result_files=['file-DlL0jGbJ1av3ZDOWEgZ9lYkW'], seed=1833498348, status='succeeded', trained_tokens=932607, training_file='file-56sdwoHCHyA2sYGrISqELhJE', validation_file='file-vA9uxpDRqnHbiJXTAg5BhPlO', estimated_finish=None, integrations=[FineTuningJobWandbIntegrationObject(type='wandb', wandb=FineTuningJobWandbIntegration(project='openai-sft', entity=None, name=None, tags=None, run_id='ftjob-8DCNlNyWerNh9zKy8U7F24Oj'))], user_provided_suffix='2440-12-weak'),\n",
       "  'final_acc': 0.907},\n",
       " {'name': '1280-128-weak',\n",
       "  'job': FineTuningJob(id='ftjob-wTTXu4HEhFKZ2WQ7U1zdvOCB', created_at=1723420121, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:1280-128-weak:9vDW8BZ0', finished_at=1723423683, hyperparameters=Hyperparameters(n_epochs=3, batch_size=2, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-5KzWCdbJZtVYV7zk2r3Ekq9H', result_files=['file-OKsJtyoLUVRa9OoHtQzqxNMq'], seed=1654820938, status='succeeded', trained_tokens=492090, training_file='file-xpxSP83JHNhxk3G2YPNo5oO9', validation_file='file-C1AUWuwqZZE4a3MuyCjvY0k2', estimated_finish=None, integrations=[FineTuningJobWandbIntegrationObject(type='wandb', wandb=FineTuningJobWandbIntegration(project='openai-sft', entity=None, name=None, tags=None, run_id='ftjob-wTTXu4HEhFKZ2WQ7U1zdvOCB'))], user_provided_suffix='1280-128-weak'),\n",
       "  'final_acc': 0.916},\n",
       " {'name': '130-243-weak',\n",
       "  'job': FineTuningJob(id='ftjob-lbnURkGplj15PPBIptMTVdHo', created_at=1723421234, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:130-243-weak:9vD7P9iu', finished_at=1723422149, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-5KzWCdbJZtVYV7zk2r3Ekq9H', result_files=['file-4JpX6kblLJWnb8yxMLGZt19X'], seed=348827182, status='succeeded', trained_tokens=44766, training_file='file-q5ZwgfhASjO5BgYhQUG5LLar', validation_file='file-DPFEPRR2n1GpaDLDfGHF5RuV', estimated_finish=None, integrations=[FineTuningJobWandbIntegrationObject(type='wandb', wandb=FineTuningJobWandbIntegration(project='openai-sft', entity=None, name=None, tags=None, run_id='ftjob-lbnURkGplj15PPBIptMTVdHo'))], user_provided_suffix='130-243-weak'),\n",
       "  'final_acc': 0.9193333333333333},\n",
       " {'name': '10240-0-weak',\n",
       "  'job': FineTuningJob(id='ftjob-t3YzlZAzHScVZsZxo7ghHGJN', created_at=1723422236, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:10240-0-weak:9vE309tZ', finished_at=1723425721, hyperparameters=Hyperparameters(n_epochs=2, batch_size=13, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-5KzWCdbJZtVYV7zk2r3Ekq9H', result_files=['file-cEEgpkPPeHOHIannHZCOoP3I'], seed=2121803333, status='succeeded', trained_tokens=2573134, training_file='file-nJeWk2URPz5yuS8z7dxoAINN', validation_file='file-Xbe1C4U7KIk0bByCsEw3B5T1', estimated_finish=None, integrations=[FineTuningJobWandbIntegrationObject(type='wandb', wandb=FineTuningJobWandbIntegration(project='openai-sft', entity=None, name=None, tags=None, run_id='ftjob-t3YzlZAzHScVZsZxo7ghHGJN'))], user_provided_suffix='10240-0-weak'),\n",
       "  'final_acc': 0.899},\n",
       " {'name': '40-60-weak',\n",
       "  'job': FineTuningJob(id='ftjob-iusqwT2y7z1zpsebyOPo6xcW', created_at=1723422989, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:40-60-weak:9vDUoziJ', finished_at=1723423601, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-5KzWCdbJZtVYV7zk2r3Ekq9H', result_files=['file-9UZz9iANWhH7lcKHtowXPTq3'], seed=104293304, status='succeeded', trained_tokens=14259, training_file='file-DPl1Zxi8HJRf2gVTfp0zlWXF', validation_file='file-nRUsWeTzb96V018rsIROcb8y', estimated_finish=None, integrations=[FineTuningJobWandbIntegrationObject(type='wandb', wandb=FineTuningJobWandbIntegration(project='openai-sft', entity=None, name=None, tags=None, run_id='ftjob-iusqwT2y7z1zpsebyOPo6xcW'))], user_provided_suffix='40-60-weak'),\n",
       "  'final_acc': 0.918},\n",
       " {'name': '9730-51-weak',\n",
       "  'job': FineTuningJob(id='ftjob-Skuh8qEeU9hl9RIzhrrTC31L', created_at=1723423617, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:9730-51-weak:9vEOx8dV', finished_at=1723427081, hyperparameters=Hyperparameters(n_epochs=2, batch_size=12, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-5KzWCdbJZtVYV7zk2r3Ekq9H', result_files=['file-iShBFDVFqL5nlRqmO1tzyGmp'], seed=534435951, status='succeeded', trained_tokens=2444042, training_file='file-ZE9wpbVmJj6rZ6QLQ9wR5KHk', validation_file='file-Gd7b3zDqpaHJtpahbOHHC68X', estimated_finish=None, integrations=[FineTuningJobWandbIntegrationObject(type='wandb', wandb=FineTuningJobWandbIntegration(project='openai-sft', entity=None, name=None, tags=None, run_id='ftjob-Skuh8qEeU9hl9RIzhrrTC31L'))], user_provided_suffix='9730-51-weak'),\n",
       "  'final_acc': 0.8983333333333333},\n",
       " {'name': '10-15-weak',\n",
       "  'job': FineTuningJob(id='ftjob-J6pQCh73IU6AvDbbqP55jv5f', created_at=1723423745, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:10-15-weak:9vDljpFa', finished_at=1723424650, hyperparameters=Hyperparameters(n_epochs=10, batch_size=1, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-5KzWCdbJZtVYV7zk2r3Ekq9H', result_files=['file-eYICKsfxC8t9cSRKpQuRfjYH'], seed=117429477, status='succeeded', trained_tokens=11390, training_file='file-EFdxkUmTogIlSs38evbRSMpj', validation_file='file-Hq4hVfpGLso2PyC8uxFAaI7Y', estimated_finish=None, integrations=[FineTuningJobWandbIntegrationObject(type='wandb', wandb=FineTuningJobWandbIntegration(project='openai-sft', entity=None, name=None, tags=None, run_id='ftjob-J6pQCh73IU6AvDbbqP55jv5f'))], user_provided_suffix='10-15-weak'),\n",
       "  'final_acc': 0.9176666666666666},\n",
       " {'name': '2560-0-weak',\n",
       "  'job': FineTuningJob(id='ftjob-IkOsEtEjxLsRP6fjdHzilYX9', created_at=1723426549, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:2560-0-weak:9vEsYVIa', finished_at=1723428916, hyperparameters=Hyperparameters(n_epochs=3, batch_size=5, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-5KzWCdbJZtVYV7zk2r3Ekq9H', result_files=['file-sOrHVF4rHIOIAgdoUn9ZJq6b'], seed=58808407, status='succeeded', trained_tokens=978840, training_file='file-tnpLjvPElCGiB4M45nqakZHc', validation_file='file-UuZiRUg1PbQAlJ62JCdJn59Y', estimated_finish=None, integrations=[FineTuningJobWandbIntegrationObject(type='wandb', wandb=FineTuningJobWandbIntegration(project='openai-sft', entity=None, name=None, tags=None, run_id='ftjob-IkOsEtEjxLsRP6fjdHzilYX9'))], user_provided_suffix='2560-0-weak'),\n",
       "  'final_acc': 0.9056666666666666},\n",
       " {'name': '160-0-oracle',\n",
       "  'job': FineTuningJob(id='ftjob-VrKEiEMvcU8zEIkOS8OgTCbB', created_at=1723420111, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:160-0-weak:9vCrKxJH', finished_at=1723421152, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-5KzWCdbJZtVYV7zk2r3Ekq9H', result_files=['file-Hf306ES5JGvPZ4VXIzAhAf10'], seed=1178864727, status='succeeded', trained_tokens=55092, training_file='file-lDqwvokl7PFqLaQUCysvooSC', validation_file='file-3vax98DB89wuM1rmPmlNbb8N', estimated_finish=None, integrations=[FineTuningJobWandbIntegrationObject(type='wandb', wandb=FineTuningJobWandbIntegration(project='openai-sft', entity=None, name=None, tags=None, run_id='ftjob-VrKEiEMvcU8zEIkOS8OgTCbB'))], user_provided_suffix='160-0-weak'),\n",
       "  'final_acc': 0.9156666666666666},\n",
       " {'name': '2440-12-oracle',\n",
       "  'job': FineTuningJob(id='ftjob-YsthpJm1nbZH4WDL71hsSuxR', created_at=1723502564, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:2440-12-oracle:9vYJQK9z', finished_at=1723503619, hyperparameters=Hyperparameters(n_epochs=8, batch_size=1, learning_rate_multiplier=1.8), model='ft:gpt-4o-mini-2024-07-18:personal:2440-12-weak:9vDKhTzx', object='fine_tuning.job', organization_id='org-5KzWCdbJZtVYV7zk2r3Ekq9H', result_files=['file-Uw8es4irvWPVTQWRC4ElxmXz'], seed=1393052693, status='succeeded', trained_tokens=19640, training_file='file-lSN5vibqZJfEYHryh5ZEUVr9', validation_file='file-4S4GRlOm3E8xLZqKM6dK56wO', estimated_finish=None, integrations=[FineTuningJobWandbIntegrationObject(type='wandb', wandb=FineTuningJobWandbIntegration(project='openai-sft', entity=None, name=None, tags=None, run_id='ftjob-YsthpJm1nbZH4WDL71hsSuxR'))], user_provided_suffix='2440-12-oracle'),\n",
       "  'final_acc': 0.905},\n",
       " {'name': '1280-128-oracle',\n",
       "  'job': FineTuningJob(id='ftjob-ThXTZNcchvIyR4BkLNKy58GV', created_at=1723506803, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:1280-128-oracle:9vZV3mjw', finished_at=1723508184, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=1.8), model='ft:gpt-4o-mini-2024-07-18:personal:1280-128-weak:9vDW8BZ0', object='fine_tuning.job', organization_id='org-5KzWCdbJZtVYV7zk2r3Ekq9H', result_files=['file-k8qx9LM62naoM4S9Em1u2mne'], seed=2098083982, status='succeeded', trained_tokens=50472, training_file='file-NGsAw1lj9WfMAS3GBOlGuHCu', validation_file='file-BYFal1fy8NLwVFnnALfc9HUq', estimated_finish=None, integrations=[FineTuningJobWandbIntegrationObject(type='wandb', wandb=FineTuningJobWandbIntegration(project='openai-sft', entity=None, name=None, tags=None, run_id='ftjob-ThXTZNcchvIyR4BkLNKy58GV'))], user_provided_suffix='1280-128-oracle'),\n",
       "  'final_acc': 0.9153333333333333},\n",
       " {'name': '130-243-oracle',\n",
       "  'job': FineTuningJob(id='ftjob-GWJFdNFNk5jKBbIqwI3i5sQY', created_at=1723506808, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:130-243-oracle:9vZUrOC1', finished_at=1723508171, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=1.8), model='ft:gpt-4o-mini-2024-07-18:personal:130-243-weak:9vD7P9iu', object='fine_tuning.job', organization_id='org-5KzWCdbJZtVYV7zk2r3Ekq9H', result_files=['file-6BiZQGyP2Px2KHuRiHaORgKh'], seed=581791080, status='succeeded', trained_tokens=92943, training_file='file-jgWGtBB1Kj4Xc11OXnJiDBXy', validation_file='file-AKVjetNoykLLW0rQT3Azyc1U', estimated_finish=None, integrations=[FineTuningJobWandbIntegrationObject(type='wandb', wandb=FineTuningJobWandbIntegration(project='openai-sft', entity=None, name=None, tags=None, run_id='ftjob-GWJFdNFNk5jKBbIqwI3i5sQY'))], user_provided_suffix='130-243-oracle'),\n",
       "  'final_acc': 0.9263333333333333},\n",
       " {'name': '10240-0-oracle',\n",
       "  'job': FineTuningJob(id='ftjob-t3YzlZAzHScVZsZxo7ghHGJN', created_at=1723422236, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:10240-0-weak:9vE309tZ', finished_at=1723425721, hyperparameters=Hyperparameters(n_epochs=2, batch_size=13, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-5KzWCdbJZtVYV7zk2r3Ekq9H', result_files=['file-cEEgpkPPeHOHIannHZCOoP3I'], seed=2121803333, status='succeeded', trained_tokens=2573134, training_file='file-nJeWk2URPz5yuS8z7dxoAINN', validation_file='file-Xbe1C4U7KIk0bByCsEw3B5T1', estimated_finish=None, integrations=[FineTuningJobWandbIntegrationObject(type='wandb', wandb=FineTuningJobWandbIntegration(project='openai-sft', entity=None, name=None, tags=None, run_id='ftjob-t3YzlZAzHScVZsZxo7ghHGJN'))], user_provided_suffix='10240-0-weak'),\n",
       "  'final_acc': 0.899},\n",
       " {'name': '0-1024-oracle',\n",
       "  'job': FineTuningJob(id='ftjob-C2OcfwlDVq5bBL1LfcfD9Nkq', created_at=1723506812, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:0-1024-oracle:9vZix0y9', finished_at=1723509045, hyperparameters=Hyperparameters(n_epochs=3, batch_size=2, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-5KzWCdbJZtVYV7zk2r3Ekq9H', result_files=['file-kH947iezMU1n2uaxBI96OUid'], seed=335036881, status='succeeded', trained_tokens=396120, training_file='file-X2Vh63w2ofwO2rlIt3Hnr81b', validation_file='file-P7sOUduU2wyqzlty8aGnl6Oa', estimated_finish=None, integrations=[FineTuningJobWandbIntegrationObject(type='wandb', wandb=FineTuningJobWandbIntegration(project='openai-sft', entity=None, name=None, tags=None, run_id='ftjob-C2OcfwlDVq5bBL1LfcfD9Nkq'))], user_provided_suffix='0-1024-oracle'),\n",
       "  'final_acc': 0.939},\n",
       " {'name': '40-60-oracle',\n",
       "  'job': FineTuningJob(id='ftjob-0uyBaznP1xoObwX4x9JGUUxW', created_at=1723508630, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:40-60-oracle:9vZnMJhE', finished_at=1723509318, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=1.8), model='ft:gpt-4o-mini-2024-07-18:personal:40-60-weak:9vDUoziJ', object='fine_tuning.job', organization_id='org-5KzWCdbJZtVYV7zk2r3Ekq9H', result_files=['file-nir6SD1r7lA9FSmC9PXauqIU'], seed=376249792, status='succeeded', trained_tokens=21360, training_file='file-yBmqXyya1BWH7m8YaNIVoQeM', validation_file='file-ydPynw6qW0NOckWiWkYLXC45', estimated_finish=None, integrations=[FineTuningJobWandbIntegrationObject(type='wandb', wandb=FineTuningJobWandbIntegration(project='openai-sft', entity=None, name=None, tags=None, run_id='ftjob-0uyBaznP1xoObwX4x9JGUUxW'))], user_provided_suffix='40-60-oracle'),\n",
       "  'final_acc': 0.9183333333333333},\n",
       " {'name': '9730-51-oracle',\n",
       "  'job': FineTuningJob(id='ftjob-NMfKmVUOudpKu8VcG7hAEoYS', created_at=1723508638, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:9730-51-oracle:9vZnBB1t', finished_at=1723509307, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=1.8), model='ft:gpt-4o-mini-2024-07-18:personal:9730-51-weak:9vEOx8dV', object='fine_tuning.job', organization_id='org-5KzWCdbJZtVYV7zk2r3Ekq9H', result_files=['file-0YO5tQfmpaLZdtyeuBXwwLVx'], seed=2029245253, status='succeeded', trained_tokens=17679, training_file='file-pom0p1v2hJdtMxnsUqt8JTrW', validation_file='file-o0e0cy02EmjS9OjcZNlZpoFx', estimated_finish=None, integrations=[FineTuningJobWandbIntegrationObject(type='wandb', wandb=FineTuningJobWandbIntegration(project='openai-sft', entity=None, name=None, tags=None, run_id='ftjob-NMfKmVUOudpKu8VcG7hAEoYS'))], user_provided_suffix='9730-51-oracle'),\n",
       "  'final_acc': 0.903},\n",
       " {'name': '10-15-oracle',\n",
       "  'job': FineTuningJob(id='ftjob-UYPGu6uaQRHgHnbDuamAH3Et', created_at=1723509851, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:10-15-oracle:9va7cW9d', finished_at=1723510574, hyperparameters=Hyperparameters(n_epochs=6, batch_size=1, learning_rate_multiplier=1.8), model='ft:gpt-4o-mini-2024-07-18:personal:10-15-weak:9vDljpFa', object='fine_tuning.job', organization_id='org-5KzWCdbJZtVYV7zk2r3Ekq9H', result_files=['file-PWo1OSE3qMLcqG0qZ3iPLpoP'], seed=1901381232, status='succeeded', trained_tokens=12072, training_file='file-iCg8UMR16B3MkZRQTDcstmdp', validation_file='file-4seuvKhWws1M8O2OaqgntSfj', estimated_finish=None, integrations=[FineTuningJobWandbIntegrationObject(type='wandb', wandb=FineTuningJobWandbIntegration(project='openai-sft', entity=None, name=None, tags=None, run_id='ftjob-UYPGu6uaQRHgHnbDuamAH3Et'))], user_provided_suffix='10-15-oracle'),\n",
       "  'final_acc': 0.9016666666666666},\n",
       " {'name': '0-4096-oracle',\n",
       "  'job': FineTuningJob(id='ftjob-26WgwdhTWTBITk4H7Zl97aoh', created_at=1723510460, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:0-4096-oracle:9vbDnnWX', finished_at=1723514801, hyperparameters=Hyperparameters(n_epochs=3, batch_size=8, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-5KzWCdbJZtVYV7zk2r3Ekq9H', result_files=['file-3PJWoDKAClLYRwH6BaN6qjai'], seed=1934750780, status='succeeded', trained_tokens=1562037, training_file='file-xJal3S6pPfACSsgjDtECcDWF', validation_file='file-2cQ5rrfGcg6eQPW2K347svWO', estimated_finish=None, integrations=[FineTuningJobWandbIntegrationObject(type='wandb', wandb=FineTuningJobWandbIntegration(project='openai-sft', entity=None, name=None, tags=None, run_id='ftjob-26WgwdhTWTBITk4H7Zl97aoh'))], user_provided_suffix='0-4096-oracle'),\n",
       "  'final_acc': 0.9616666666666667},\n",
       " {'name': '0-16-oracle',\n",
       "  'job': FineTuningJob(id='ftjob-XaQGa1quJa0Wa674vB7in2LE', created_at=1723510465, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:0-16-oracle:9vaIxLnZ', finished_at=1723511278, hyperparameters=Hyperparameters(n_epochs=6, batch_size=1, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-5KzWCdbJZtVYV7zk2r3Ekq9H', result_files=['file-2Lro7TreeE6phKoOeKNgQZ2a'], seed=1310819200, status='succeeded', trained_tokens=11388, training_file='file-VjReTASmGzmBDRuscrJPLEeh', validation_file='file-iaG0LklOZUTPC5wqCqr3pXi8', estimated_finish=None, integrations=[FineTuningJobWandbIntegrationObject(type='wandb', wandb=FineTuningJobWandbIntegration(project='openai-sft', entity=None, name=None, tags=None, run_id='ftjob-XaQGa1quJa0Wa674vB7in2LE'))], user_provided_suffix='0-16-oracle'),\n",
       "  'final_acc': 0.9256666666666666},\n",
       " {'name': '2560-0-oracle',\n",
       "  'job': FineTuningJob(id='ftjob-IkOsEtEjxLsRP6fjdHzilYX9', created_at=1723426549, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:2560-0-weak:9vEsYVIa', finished_at=1723428916, hyperparameters=Hyperparameters(n_epochs=3, batch_size=5, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-5KzWCdbJZtVYV7zk2r3Ekq9H', result_files=['file-sOrHVF4rHIOIAgdoUn9ZJq6b'], seed=58808407, status='succeeded', trained_tokens=978840, training_file='file-tnpLjvPElCGiB4M45nqakZHc', validation_file='file-UuZiRUg1PbQAlJ62JCdJn59Y', estimated_finish=None, integrations=[FineTuningJobWandbIntegrationObject(type='wandb', wandb=FineTuningJobWandbIntegration(project='openai-sft', entity=None, name=None, tags=None, run_id='ftjob-IkOsEtEjxLsRP6fjdHzilYX9'))], user_provided_suffix='2560-0-weak'),\n",
       "  'final_acc': 0.9056666666666666}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import Client\n",
    "import json\n",
    "\n",
    "client = Client()\n",
    "\n",
    "with open(\"openai/jobs.json\", \"r\") as f:\n",
    "    jobs = json.load(f)\n",
    "\n",
    "runs = []\n",
    "for name in jobs:\n",
    "    job_id = jobs[name].get(\"job\", jobs[name].get(\"weak_job\"))[\"id\"]\n",
    "    job = client.fine_tuning.jobs.retrieve(fine_tuning_job_id=job_id)\n",
    "    events = client.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id, limit=10)\n",
    "    final_acc = [e.data[\"full_valid_mean_token_accuracy\"] for e in events if e.type == \"metrics\" and \"full_valid_mean_token_accuracy\" in e.data][0]\n",
    "    if job.status == \"succeeded\":\n",
    "        runs.append({\n",
    "            \"name\": name,\n",
    "            \"job\": job,\n",
    "            \"final_acc\": final_acc,\n",
    "        })\n",
    "    print(f\"{name}: {job.status}\")\n",
    "runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'job': {'id': 'ftjob-VrKEiEMvcU8zEIkOS8OgTCbB',\n",
       "  'created_at': 1723420111,\n",
       "  'error': {'code': None, 'message': None, 'param': None},\n",
       "  'fine_tuned_model': None,\n",
       "  'finished_at': None,\n",
       "  'hyperparameters': {'n_epochs': 'auto',\n",
       "   'batch_size': 'auto',\n",
       "   'learning_rate_multiplier': 'auto'},\n",
       "  'model': 'gpt-4o-mini-2024-07-18',\n",
       "  'object': 'fine_tuning.job',\n",
       "  'organization_id': 'org-5KzWCdbJZtVYV7zk2r3Ekq9H',\n",
       "  'result_files': [],\n",
       "  'seed': 1178864727,\n",
       "  'status': 'validating_files',\n",
       "  'trained_tokens': None,\n",
       "  'training_file': 'file-lDqwvokl7PFqLaQUCysvooSC',\n",
       "  'validation_file': 'file-3vax98DB89wuM1rmPmlNbb8N',\n",
       "  'estimated_finish': None,\n",
       "  'integrations': [{'type': 'wandb',\n",
       "    'wandb': {'project': 'openai-sft',\n",
       "     'entity': None,\n",
       "     'name': None,\n",
       "     'tags': None,\n",
       "     'run_id': 'ftjob-VrKEiEMvcU8zEIkOS8OgTCbB'}}],\n",
       "  'user_provided_suffix': '160-0-weak'},\n",
       " 'train_file_id': 'file-lDqwvokl7PFqLaQUCysvooSC',\n",
       " 'val_file_id': 'file-3vax98DB89wuM1rmPmlNbb8N'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs[name]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "w2s2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
